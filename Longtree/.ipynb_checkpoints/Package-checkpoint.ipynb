{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source(\"SimData.r\")\n",
    "library(\"glmertree\")\n",
    "library(\"WGCNA\")\n",
    "library(\"pre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems\n",
    "* When fixed_regress = NULL, we can let the user decide whether to use PC or not as regressors. If don't use PC, that is a WGCNA+ regular RE-EM\n",
    "* Right now we can only do random intercept\n",
    "* User may want to tune other parameters in WGCNA (in addition to power). How to do this in a elegant way? (Not urgent since the current parameters can cluster correctly)\n",
    "* max_depth_screen_factor=0.04 and max_depth_select_factor = 0.8 (not urgent)\n",
    "* Right now all the alpha in the algorithm are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not finished\n",
    "* In Longtree function where fixed_regress ==NULL, just use PC and glmertree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: a glmertree object (trained tree)\n",
    "\n",
    "Parameters:\n",
    "* data: training data\n",
    "* fixed_regress: the regressors used no matter what such as time and time^2; if fixed_regress = NULL, use PC as regressor at screening step\n",
    "* fixed_split: a char vector containing features definitely used in splitting\n",
    "* var_select: a char vector containing features to be selected. These features will be clustered by WGCNA and the chosen ones will be used in regression and splitting\n",
    "* power: parameters of WGCNA\n",
    "* cluster: the variable name of each cluster (in terms of random effect)\n",
    "* Fuzzy = TRUE: Screen like Fuzzy Forest; Fuzzy= FALSE: first screen within non-grey modules and then select the final non-grey features within the selected ones from each non-grey module; Use this final non-grey features as regressors (plus fixed_regress) and use grey features as split_var to select grey features. The use final non-grey features and selected grey features together in splitting and regression variables, to do the final prediction. Fuzzy=FALSE is used if there are so many non-grey features and you want to protect grey features.\n",
    "* maxdepth_factor_screen: when selecting features from one module, the maxdepth of the glmertree is set to ceiling function of maxdepth_factor_screen*(#features in that module). Default is 0.04. \n",
    "* maxdepth_factor_select: Given screened features (from each modules, if Fuzzy=FALSE,that is the selected non-grey features from each non-grey modules), we want to select again from those screened features. The maxdepth of that glmertree is set to be ceiling of maxdepth_factor_select*(#screened features). Default is 0.6.\n",
    "* for the maxdepth of the prediction tree (final tree), maxdepth is set to the length of the split_var (fixed+chosen ones)\n",
    "* The most important parameters are alpha and maxdepth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Longtree = function(data,fixed_regress=NULL,fixed_split=NULL,var_select=NULL,\n",
    "                    power=6,cluster,alpha=0.2,maxdepth_factor_screen=0.04,\n",
    "                    maxdepth_factor_select=0.5,Fuzzy=TRUE){\n",
    "    ### if there are no features to select, just use fixed_regress and fixed_split\n",
    "    if(length(var_select)==0){\n",
    "        if (length(fixed_regress)==0){\n",
    "            if (length(fixed_split)==0){\n",
    "                stop(\"no features to split and regress on\")\n",
    "            }\n",
    "            fixed_regress = \"1\"\n",
    "        }\n",
    "        maxdepth = length(fixed_split)\n",
    "        Formula = as.formula(paste(\"y~\",paste(fixed_regress,collapse = \"+\"),\n",
    "                                       \"|\",cluster,\"|\",\n",
    "                                     paste(fixed_split,collapse = \"+\")))\n",
    "        mytree = lmertree(Formula, data = data,alpha = alpha,maxdepth=maxdepth)\n",
    "        return (mytree)\n",
    "    } ###\n",
    "    # Now var_select is not empty\n",
    "    # If don't specify fixed_regress: use PC as regressors at screening step\n",
    "    if (length(fixed_regress)==0){\n",
    "        ...\n",
    "        return\n",
    "    }###\n",
    "    # Now we have non-empty var_select,fixed_regress\n",
    "    return(Longtree_time(data=data,fixed_regress=fixed_regress,\n",
    "                        fixed_split=fixed_split, var_select=var_select,\n",
    "                    power=power,cluster=cluster,alpha=alpha,\n",
    "                    maxdepth_factor_screen=maxdepth_factor_screen, \n",
    "                    maxdepth_factor_select=maxdepth_factor_select,Fuzzy=Fuzzy))\n",
    "                        \n",
    "}\n",
    "\n",
    "# Longtree_time: used when var_select and fixed_regress are non-empty\n",
    "# Longtree is equivalent to this Longtree_time in this case\n",
    "Longtree_time = function(data,fixed_regress,fixed_split,var_select,power,cluster,\n",
    "                         alpha,maxdepth_factor_screen,maxdepth_factor_select,Fuzzy){\n",
    "    # Cluster var_select\n",
    "    data_WGCNA = data[var_select]\n",
    "    # Must set numericLabels = FALSE so that it uses actual colors like \"grey\"\n",
    "    net = blockwiseModules(data_WGCNA, power = power,TOMType = \"unsigned\", \n",
    "                           minModuleSize = 30,reassignThreshold = 0, \n",
    "                           mergeCutHeight = 0.25,numericLabels = FALSE, \n",
    "                           pamRespectsDendro = FALSE,verbose = 0)\n",
    "    # the correspondance betweeen feature names and colors\n",
    "    colors = net$colors # it is a string vector with names (that is the name is V1)\n",
    "    module_names = unique(colors) # all color names\n",
    "    #\"dictionary\"with keys=name of color,values=names of features of that color\n",
    "    module_dic = list() \n",
    "    for (i in 1:length(module_names)){\n",
    "        module_dic[[module_names[i]]] = names(colors[colors==module_names[i]])\n",
    "    }\n",
    "    \n",
    "    imp_var = list() # used to store the names of important features\n",
    "    \n",
    "    if(Fuzzy==TRUE){\n",
    "        # Do the selection step just like Fuzzy Forest:\n",
    "        # for each module (including grey), use them as split_var and select\n",
    "        # finally, use all selected ones as split_var and select\n",
    "        \n",
    "        for (name in module_names){\n",
    "        # in the formula, add fixed_split as split_var, also include the module features\n",
    "        split_var = c(module_dic[[name]],fixed_split)\n",
    "        maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "        # use fixed_regress as regressor\n",
    "        regress_var = fixed_regress\n",
    "\n",
    "        # Formula for lmtree\n",
    "        Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                               \"|\",cluster,\"|\",\n",
    "                    paste(split_var,collapse = \"+\")))\n",
    "\n",
    "        # fit the tree\n",
    "        mytree = lmertree(Formula, data = data,alpha = alpha,maxdepth=maxdepth) \n",
    "\n",
    "        #extract important features\n",
    "        imp_var[[length(imp_var)+1]] = get_split_names(mytree$tree,data)\n",
    "        }\n",
    "        \n",
    "        # the variables selected from all the modules\n",
    "        final_var = imp_var[[1]]\n",
    "        if (length(imp_var)>1){\n",
    "            # There are at least 2 modules\n",
    "            for (i in 2:length(imp_var)){\n",
    "            final_var = c(final_var,imp_var[[i]])\n",
    "         }\n",
    "            cat(\"after screening within modules\",final_var,\"\\n\")\n",
    "            \n",
    "            # the final selection among all the chosen features \n",
    "            regress_var = fixed_regress\n",
    "            split_var = c(final_var,fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_select*length(split_var))\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                       \"|\",cluster,\"|\",\n",
    "                                     paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data = data,alpha = alpha,maxdepth=maxdepth) \n",
    "            final_var = get_split_names(mytree$tree,data)\n",
    "            cat(\"final features\",final_var)      \n",
    "        }else{\n",
    "            # only grey module\n",
    "            cat(\"There is only one module, final features\",final_var)\n",
    "        }\n",
    "        # use the final features as split&regression variables\n",
    "        split_var = c(final_var,fixed_split)\n",
    "        maxdepth = length(split_var)\n",
    "        regress_var = c(fixed_regress,final_var)\n",
    "        Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "        mytree = lmertree(Formula, data = data,alpha=alpha,maxdepth=maxdepth) \n",
    "        return(mytree)           \n",
    "    }\n",
    "    if(Fuzzy==FALSE){\n",
    "        # first do the screening and selecting in non-grey modules\n",
    "        # Then use those non-grey estimated true features as regressors\n",
    "        # and grey features as split_var, choose grey features and keep them\n",
    "        for (name in module_names){\n",
    "        if(name==\"grey\"){\n",
    "            next\n",
    "        }\n",
    "        split_var = c(module_dic[[name]],fixed_split)\n",
    "        maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "        regress_var = fixed_regress\n",
    "\n",
    "        # Formula for lmtree\n",
    "        Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                               \"|\",cluster,\"|\",\n",
    "                    paste(split_var,collapse = \"+\")))\n",
    "\n",
    "        # fit the tree\n",
    "        mytree = lmertree(Formula, data = data,alpha = alpha,maxdepth=maxdepth) \n",
    "\n",
    "        #extract important features\n",
    "        imp_var[[length(imp_var)+1]] = get_split_names(mytree$tree,data)\n",
    "        }# Now imp_var contains important features from modules that are not grey\n",
    "        if(length(imp_var)==0){\n",
    "            # only grey module, no other modules\n",
    "            split_var = c(module_dic[[\"grey\"]],fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "            regress_var = fixed_regress\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                               \"|\",cluster,\"|\",\n",
    "                    paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data = data,alpha = alpha,maxdepth=maxdepth) \n",
    "            final_var = get_split_names(mytree$tree,data)\n",
    "            cat(\"There is only one module which is grey, final features\",final_var)\n",
    "        }else{\n",
    "            # at least one non-grey module\n",
    "            final_var = imp_var[[1]]\n",
    "            # if only one non-grey module: final_var is the chosen non-grey features\n",
    "            # if at least two non-grey modules:\n",
    "            if (length(imp_var)>1){\n",
    "                # There are at least 2 modules\n",
    "                for (i in 2:length(imp_var)){\n",
    "                final_var = c(final_var,imp_var[[i]])\n",
    "                }\n",
    "            \n",
    "            cat(\"After screening within non-grey modules\",final_var,\"\\n\")\n",
    "            # select from selected non-grey features\n",
    "            regress_var = fixed_regress\n",
    "            split_var = c(final_var,fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_select*length(split_var))\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                       \"|\",cluster,\"|\",\n",
    "                                     paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data = data,alpha = alpha,maxdepth=maxdepth) \n",
    "            final_var = get_split_names(mytree$tree,data)\n",
    "            }\n",
    "            cat(\"The chosen non-grey features are\",final_var,\"\\n\")\n",
    "            \n",
    "            # use final_var (chosen non-grey features) to select grey features\n",
    "            regress_var = c(fixed_regress,final_var)\n",
    "            split_var = c(module_dic[[\"grey\"]],fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                       \"|\",cluster,\"|\",\n",
    "                                     paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data = data,alpha = alpha,maxdepth=maxdepth) \n",
    "            grey_var = get_split_names(mytree$tree,data)\n",
    "            cat(\"The chosen grey features are\",grey_var,\"\\n\")\n",
    "            # use final_var and grey_var do to the final model tree\n",
    "            final_var = c(final_var,grey_var)    \n",
    "            cat(\"final features\",final_var)  \n",
    "        }\n",
    "        # use the final features as split&regression variables\n",
    "        split_var = c(final_var,fixed_split)\n",
    "        maxdepth = length(split_var)\n",
    "        regress_var = c(fixed_regress,final_var)\n",
    "        Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "        mytree = lmertree(Formula, data = data,alpha=alpha,maxdepth=maxdepth) \n",
    "        return(mytree)\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "# Methods for extracting names of splitting features used in a tree\n",
    "# tree: a tree object; data: the train or test set\n",
    "get_split_names = function(tree,data){\n",
    "    # path: the string that contains all the node information\n",
    "    paths <- pre:::list.rules(tree, removecomplements = FALSE)\n",
    "    vnames = names(data)\n",
    "    # the regex for a variable\n",
    "    # tomatch = paste(paste(var,\"<=\"),\"|\",paste(var,\">\"),sep=\"\")\n",
    "    # match to tomatch in path\n",
    "    tmp = vnames[sapply(sapply(vnames, FUN = function(var) grep(paste(paste(var,\"<=\"),\"|\",paste(var,\">\"),sep=\"\"), paths)), length) > 0]\n",
    "    return (tmp)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_regress = c(\"time\",\"time2\")\n",
    "fixed_split = c(\"treatment\")\n",
    "cluster = \"patient\"\n",
    "var_select = paste(\"V\",1:400,sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "n <- 300 # number of patients\n",
    "T <-  5 # number of observations per patients\n",
    "\n",
    "set.seed(100)\n",
    "\n",
    "data <- sim_quad(n,T)\n",
    "# add time_squared\n",
    "data$time2 = (data$time)^2\n",
    "\n",
    "# testing data\n",
    "n_test <- 100 # number of patients\n",
    "T <-  5 # number of observations per patients\n",
    "set.seed(101)\n",
    "data_test <- sim_quad(n,T)\n",
    "# data_test <- sim_quad(n_test, T)\n",
    "data_test$time2 = (data_test$time)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "boundary (singular) fit: see ?isSingular\n",
      "boundary (singular) fit: see ?isSingular\n",
      "boundary (singular) fit: see ?isSingular\n",
      "boundary (singular) fit: see ?isSingular\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after screening within modules V1 V2 V3 V14 V26 V68 V106 V154 V172 V301 V302 V303 V319 V348 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "boundary (singular) fit: see ?isSingular\n",
      "boundary (singular) fit: see ?isSingular\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final features V1 V2 V3 V14 V26 V301 V302 V303"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  20.00    0.46   20.61 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16.5247519487391"
      ],
      "text/latex": [
       "16.5247519487391"
      ],
      "text/markdown": [
       "16.5247519487391"
      ],
      "text/plain": [
       "[1] 16.52475"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fuzzy=TRUE \n",
    "# alpha = 0.2, maxdepth_factor_select = 0.5 (all default)\n",
    "system.time({\n",
    "    mytree = Longtree(data,fixed_regress=fixed_regress,fixed_split=fixed_split,\n",
    "                  var_select=var_select,cluster=cluster,Fuzzy=TRUE)\n",
    "})\n",
    "mean((predict(mytree,newdata=data_test)-data_test$y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "boundary (singular) fit: see ?isSingular\n",
      "boundary (singular) fit: see ?isSingular\n",
      "boundary (singular) fit: see ?isSingular\n",
      "boundary (singular) fit: see ?isSingular\n",
      "boundary (singular) fit: see ?isSingular\n",
      "boundary (singular) fit: see ?isSingular\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After screening within non-grey modules V1 V2 V3 V14 V26 V68 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "boundary (singular) fit: see ?isSingular\n",
      "boundary (singular) fit: see ?isSingular\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chosen non-grey features are V1 V2 V3 \n",
      "The chosen grey features are V301 V302 V303 \n",
      "final features V1 V2 V3 V301 V302 V303"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  21.39    0.34   21.59 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "14.1631483253277"
      ],
      "text/latex": [
       "14.1631483253277"
      ],
      "text/markdown": [
       "14.1631483253277"
      ],
      "text/plain": [
       "[1] 14.16315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fuzzy=False \n",
    "# alpha = 0.1, maxdepth_factor_select = 0.5\n",
    "system.time({\n",
    "    mytree = Longtree(data,fixed_regress=fixed_regress,fixed_split=fixed_split,\n",
    "                  var_select=var_select,alpha=0.1,cluster=cluster,Fuzzy=FALSE)\n",
    "})\n",
    "mean((predict(mytree,newdata=data_test)-data_test$y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "randomForest 4.6-14\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Attaching package: 'randomForest'\n",
      "\n",
      "The following object is masked from 'package:pre':\n",
      "\n",
      "    importance\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  79.92    0.08   81.16 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "69.9113394649131"
      ],
      "text/latex": [
       "69.9113394649131"
      ],
      "text/markdown": [
       "69.9113394649131"
      ],
      "text/plain": [
       "[1] 69.91134"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'treatment'</li>\n",
       "\t<li>'time2'</li>\n",
       "\t<li>'time'</li>\n",
       "\t<li>'V3'</li>\n",
       "\t<li>'V301'</li>\n",
       "\t<li>'V1'</li>\n",
       "\t<li>'V2'</li>\n",
       "\t<li>'V58'</li>\n",
       "\t<li>'V302'</li>\n",
       "\t<li>'V42'</li>\n",
       "\t<li>'V24'</li>\n",
       "\t<li>'V303'</li>\n",
       "\t<li>'V14'</li>\n",
       "\t<li>'V72'</li>\n",
       "\t<li>'V22'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'treatment'\n",
       "\\item 'time2'\n",
       "\\item 'time'\n",
       "\\item 'V3'\n",
       "\\item 'V301'\n",
       "\\item 'V1'\n",
       "\\item 'V2'\n",
       "\\item 'V58'\n",
       "\\item 'V302'\n",
       "\\item 'V42'\n",
       "\\item 'V24'\n",
       "\\item 'V303'\n",
       "\\item 'V14'\n",
       "\\item 'V72'\n",
       "\\item 'V22'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'treatment'\n",
       "2. 'time2'\n",
       "3. 'time'\n",
       "4. 'V3'\n",
       "5. 'V301'\n",
       "6. 'V1'\n",
       "7. 'V2'\n",
       "8. 'V58'\n",
       "9. 'V302'\n",
       "10. 'V42'\n",
       "11. 'V24'\n",
       "12. 'V303'\n",
       "13. 'V14'\n",
       "14. 'V72'\n",
       "15. 'V22'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"treatment\" \"time2\"     \"time\"      \"V3\"        \"V301\"      \"V1\"       \n",
       " [7] \"V2\"        \"V58\"       \"V302\"      \"V42\"       \"V24\"       \"V303\"     \n",
       "[13] \"V14\"       \"V72\"       \"V22\"      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# random forest\n",
    "library(\"randomForest\")\n",
    "var = c(paste(\"V\",1:400,sep=\"\"),\"time\",\"time2\",\"treatment\")\n",
    "Formula = as.formula(paste(\"y~\",paste(var,collapse = \"+\")))\n",
    "system.time({\n",
    "#     set.seed(20)\n",
    "    rf <- randomForest(Formula,data)\n",
    "})\n",
    "mean((predict(rf,newdata=data_test)-data_test$y)**2)\n",
    "# sorts features by importance\n",
    "importance_order <- sort(rf$importance, decreasing = TRUE,index.return=TRUE) \n",
    "# the ranking; 6 here should be a parameters\n",
    "var[importance_order$ix[1:15]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'fuzzyforest' was built under R version 3.6.1\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       " 576.29    1.97  581.92 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "45.3344670313764"
      ],
      "text/latex": [
       "45.3344670313764"
      ],
      "text/markdown": [
       "45.3344670313764"
      ],
      "text/plain": [
       "[1] 45.33447"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'treatment'</li>\n",
       "\t<li>'time2'</li>\n",
       "\t<li>'time'</li>\n",
       "\t<li>'V3'</li>\n",
       "\t<li>'V1'</li>\n",
       "\t<li>'V2'</li>\n",
       "\t<li>'V301'</li>\n",
       "\t<li>'V24'</li>\n",
       "\t<li>'V71'</li>\n",
       "\t<li>'V302'</li>\n",
       "\t<li>'V303'</li>\n",
       "\t<li>'V208'</li>\n",
       "\t<li>'V247'</li>\n",
       "\t<li>'V284'</li>\n",
       "\t<li>'V106'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'treatment'\n",
       "\\item 'time2'\n",
       "\\item 'time'\n",
       "\\item 'V3'\n",
       "\\item 'V1'\n",
       "\\item 'V2'\n",
       "\\item 'V301'\n",
       "\\item 'V24'\n",
       "\\item 'V71'\n",
       "\\item 'V302'\n",
       "\\item 'V303'\n",
       "\\item 'V208'\n",
       "\\item 'V247'\n",
       "\\item 'V284'\n",
       "\\item 'V106'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'treatment'\n",
       "2. 'time2'\n",
       "3. 'time'\n",
       "4. 'V3'\n",
       "5. 'V1'\n",
       "6. 'V2'\n",
       "7. 'V301'\n",
       "8. 'V24'\n",
       "9. 'V71'\n",
       "10. 'V302'\n",
       "11. 'V303'\n",
       "12. 'V208'\n",
       "13. 'V247'\n",
       "14. 'V284'\n",
       "15. 'V106'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"treatment\" \"time2\"     \"time\"      \"V3\"        \"V1\"        \"V2\"       \n",
       " [7] \"V301\"      \"V24\"       \"V71\"       \"V302\"      \"V303\"      \"V208\"     \n",
       "[13] \"V247\"      \"V284\"      \"V106\"     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fuzzy Forest\n",
    "library(\"fuzzyforest\")\n",
    "# since treatment is categorical, we cannot include it in WGCNA\n",
    "system.time({\n",
    "data_WGCNA = data[,1:400] # only the covariates\n",
    "\n",
    "net = blockwiseModules(data_WGCNA, power = 6,TOMType = \"unsigned\", \n",
    "                       minModuleSize = 30,reassignThreshold = 0, \n",
    "                       mergeCutHeight = 0.25,numericLabels = FALSE, \n",
    "                       pamRespectsDendro = FALSE,verbose = 0)\n",
    "\n",
    "var = c(paste(\"V\",1:400,sep=\"\"),\"time\",\"time2\",\"treatment\")\n",
    "Formula = as.formula(paste(\"y~\",paste(var,collapse = \"+\")))\n",
    "    \n",
    "net$colors[[\"time\"]] = \"grey\"\n",
    "net$colors[[\"time2\"]] = \"grey\"\n",
    "net$colors[[\"treatment\"]] = \"grey\"\n",
    "\n",
    "ff_fit = ff(Formula,data = data,module_membership=net$colors,\n",
    "        screen_params = screen_control(min_ntree = 500),\n",
    "        select_params = select_control(min_ntree = 500,number_selected = 15), \n",
    "        final_ntree = 5000, num_processors = 1)        \n",
    "})\n",
    "mean((predict(ff_fit,new_data=data_test)-data_test$y)**2)\n",
    "ff_fit$feature_list[,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
