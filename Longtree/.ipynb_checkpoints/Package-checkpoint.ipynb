{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "source(\"SimData.r\")\n",
    "library(\"glmertree\")\n",
    "library(\"WGCNA\")\n",
    "library(\"pre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems\n",
    "* When fixed_regress = NULL, we can let the user decide whether to use PC or not as regressors. If don't use PC, that is a WGCNA+ regular RE-EM\n",
    "* Right now we can only do random intercept\n",
    "* User may want to tune other parameters in WGCNA (in addition to power). How to do this in a elegant way? (Not urgent since the current parameters can cluster correctly)\n",
    "* Right now all the alpha in the algorithm are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: a glmertree object (trained tree)\n",
    "\n",
    "Parameters:\n",
    "* data: training data\n",
    "* fixed_regress: the regressors used no matter what such as time and time^2; if fixed_regress = NULL, use PC as regressor at screening step\n",
    "* fixed_split: a char vector containing features definitely used in splitting\n",
    "* var_select: a char vector containing features to be selected. These features will be clustered by WGCNA and the chosen ones will be used in regression and splitting\n",
    "* power: parameters of WGCNA\n",
    "* cluster: the variable name of each cluster (in terms of random effect)\n",
    "* Fuzzy = TRUE: Screen like Fuzzy Forest; Fuzzy= FALSE: first screen within non-grey modules and then select the final non-grey features within the selected ones from each non-grey module; Use this final non-grey features as regressors (plus fixed_regress) and use grey features as split_var to select grey features. The use final non-grey features and selected grey features together in splitting and regression variables, to do the final prediction. Fuzzy=FALSE is used if there are so many non-grey features and you want to protect grey features.\n",
    "* maxdepth_factor_screen: when selecting features from one module, the maxdepth of the glmertree is set to ceiling function of maxdepth_factor_screen*(#features in that module). Default is 0.04. \n",
    "* maxdepth_factor_select: Given screened features (from each modules, if Fuzzy=FALSE,that is the selected non-grey features from each non-grey modules), we want to select again from those screened features. The maxdepth of that glmertree is set to be ceiling of maxdepth_factor_select*(#screened features). Default is 0.6.\n",
    "* for the maxdepth of the prediction tree (final tree), maxdepth is set to the length of the split_var (fixed+chosen ones)\n",
    "* minsize_multiplier: At the final prediction tree, the minsize = minsize_multiplier times thelength of final regressors. The default is 5. Note that we only set minsize for the final prediction tree instead of trees at the feature selection step since during feature selection, we don't have to be so careful. Note that when tuning the parameters, larger alpha and samller minsize_multiplier will result in deeper tree and therefore may cause overfitting problem. You'd better decrease alpha and decrease minsize_multiplier at the same time.\n",
    "* alpha_screen, alpha_select and alpha_predict are the alpha used in trees and the screening, selecting and preidition step respectively.\n",
    "* The most important parameters are alpha, maxdepth and minsize_multiplier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Longtree = function(data,fixed_regress=NULL,fixed_split=NULL,var_select=NULL,\n",
    "                    power=6,cluster,alpha=0.2,maxdepth_factor_screen=0.04,\n",
    "                    maxdepth_factor_select=0.5,Fuzzy=TRUE,\n",
    "                    minsize_multiplier = 5){\n",
    "    ### if there are no features to select, just use fixed_regress and fixed_split\n",
    "    if(length(var_select)==0){\n",
    "        if (length(fixed_regress)==0){\n",
    "            if (length(fixed_split)==0){\n",
    "                stop(\"no features to split and regress on\")\n",
    "            }\n",
    "            fixed_regress = \"1\"\n",
    "        }\n",
    "        maxdepth = length(fixed_split)\n",
    "        Formula = as.formula(paste(\"y~\",paste(fixed_regress,collapse = \"+\"),\n",
    "                                       \"|\",cluster,\"|\",\n",
    "                                     paste(fixed_split,collapse = \"+\")))\n",
    "        mytree = lmertree(Formula, data = data,alpha = alpha,maxdepth=maxdepth)\n",
    "        mytree$final_selection = NULL\n",
    "        return (mytree)\n",
    "    } ###\n",
    "    # Now var_select is not empty\n",
    "    # If don't specify fixed_regress: use PC as regressors at screening step\n",
    "    if (length(fixed_regress)==0){\n",
    "        cat(\"Use Longtree_PC\\n\")\n",
    "        return(Longtree_PC(data=data,fixed_split=fixed_split,\n",
    "                    var_select=var_select,\n",
    "                    power=power,cluster=cluster,alpha=alpha,\n",
    "                    maxdepth_factor_screen=maxdepth_factor_screen, \n",
    "                    maxdepth_factor_select=maxdepth_factor_select,Fuzzy=Fuzzy,\n",
    "                    minsize_multiplier=minsize_multiplier))\n",
    "    }###\n",
    "    # Now we have non-empty var_select,fixed_regress\n",
    "    cat(\"Use Longtree_time\\n\")\n",
    "    return(Longtree_time(data=data,fixed_regress=fixed_regress,\n",
    "                        fixed_split=fixed_split, var_select=var_select,\n",
    "                    power=power,cluster=cluster,alpha=alpha,\n",
    "                    maxdepth_factor_screen=maxdepth_factor_screen, \n",
    "                    maxdepth_factor_select=maxdepth_factor_select,Fuzzy=Fuzzy,\n",
    "                    minsize_multiplier=minsize_multiplier))\n",
    "                        \n",
    "}\n",
    "\n",
    "# Longtree_time: used when var_select and fixed_regress are non-empty\n",
    "# Longtree is equivalent to this Longtree_time in this case\n",
    "Longtree_time = function(data,fixed_regress,fixed_split,var_select,power,cluster,\n",
    "                         alpha,maxdepth_factor_screen,maxdepth_factor_select,\n",
    "                         Fuzzy,minsize_multiplier){\n",
    "    # Cluster var_select\n",
    "    data_WGCNA = data[var_select]\n",
    "    # Must set numericLabels = FALSE so that it uses actual colors like \"grey\"\n",
    "    net = blockwiseModules(data_WGCNA, power = power,TOMType = \"unsigned\", \n",
    "                           minModuleSize = 30,reassignThreshold = 0, \n",
    "                           mergeCutHeight = 0.25,numericLabels = FALSE, \n",
    "                           pamRespectsDendro = FALSE,verbose = 0)\n",
    "    # the correspondance betweeen feature names and colors\n",
    "    colors = net$colors # it is a string vector with names (that is the name is V1)\n",
    "    module_names = unique(colors) # all color names\n",
    "    #\"dictionary\"with keys=name of color,values=names of features of that color\n",
    "    module_dic = list() \n",
    "    for (i in 1:length(module_names)){\n",
    "        module_dic[[module_names[i]]] = names(colors[colors==module_names[i]])\n",
    "    }\n",
    "    \n",
    "    imp_var = list() # used to store the names of important features\n",
    "    \n",
    "    if(Fuzzy==TRUE){\n",
    "        # Do the selection step just like Fuzzy Forest:\n",
    "        # for each module (including grey), use them as split_var and select\n",
    "        # finally, use all selected ones as split_var and select\n",
    "        \n",
    "        for (name in module_names){\n",
    "        # in the formula, add fixed_split as split_var, also include the module features\n",
    "        split_var = c(module_dic[[name]],fixed_split)\n",
    "        maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "        # use fixed_regress as regressor\n",
    "        regress_var = fixed_regress\n",
    "\n",
    "        # Formula for lmtree\n",
    "        Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                               \"|\",cluster,\"|\",\n",
    "                    paste(split_var,collapse = \"+\")))\n",
    "\n",
    "        # fit the tree\n",
    "        mytree = lmertree(Formula, data = data,alpha = alpha,maxdepth=maxdepth) \n",
    "\n",
    "        #extract important features\n",
    "        imp_var[[length(imp_var)+1]] = get_split_names(mytree$tree,data)\n",
    "        }\n",
    "        \n",
    "        # the variables selected from all the modules\n",
    "        final_var = imp_var[[1]]\n",
    "        if (length(imp_var)>1){\n",
    "            # There are at least 2 modules\n",
    "            for (i in 2:length(imp_var)){\n",
    "            final_var = c(final_var,imp_var[[i]])\n",
    "         }\n",
    "            cat(\"after screening within modules\",final_var,\"\\n\")\n",
    "            \n",
    "            # the final selection among all the chosen features \n",
    "            regress_var = fixed_regress\n",
    "            split_var = c(final_var,fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_select*length(split_var))\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                       \"|\",cluster,\"|\",\n",
    "                                     paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data = data,alpha = alpha,maxdepth=maxdepth) \n",
    "            final_var = get_split_names(mytree$tree,data)\n",
    "            cat(\"final features\",final_var)      \n",
    "        }else{\n",
    "            # only grey module\n",
    "            cat(\"There is only one module, final features\",final_var)\n",
    "        }\n",
    "        # use the final features as split&regression variables\n",
    "        split_var = c(final_var,fixed_split)\n",
    "        maxdepth = length(split_var)\n",
    "        regress_var = c(fixed_regress,final_var)\n",
    "        Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "        minsize = round(minsize_multiplier*length(regress_var))\n",
    "        mytree = lmertree(Formula, data = data,alpha=alpha,maxdepth=maxdepth,\n",
    "                         minsize = minsize)\n",
    "        mytree$final_selection = final_var\n",
    "        return(mytree)           \n",
    "    }\n",
    "    if(Fuzzy==FALSE){\n",
    "        # first do the screening and selecting in non-grey modules\n",
    "        # Then use those non-grey estimated true features as regressors\n",
    "        # and grey features as split_var, choose grey features and keep them\n",
    "        for (name in module_names){\n",
    "        if(name==\"grey\"){\n",
    "            next\n",
    "        }\n",
    "        split_var = c(module_dic[[name]],fixed_split)\n",
    "        maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "        regress_var = fixed_regress\n",
    "\n",
    "        # Formula for lmtree\n",
    "        Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                               \"|\",cluster,\"|\",\n",
    "                    paste(split_var,collapse = \"+\")))\n",
    "\n",
    "        # fit the tree\n",
    "        mytree = lmertree(Formula, data = data,alpha = alpha,maxdepth=maxdepth) \n",
    "\n",
    "        #extract important features\n",
    "        imp_var[[length(imp_var)+1]] = get_split_names(mytree$tree,data)\n",
    "        }# Now imp_var contains important features from modules that are not grey\n",
    "        if(length(imp_var)==0){\n",
    "            # only grey module, no other modules\n",
    "            split_var = c(module_dic[[\"grey\"]],fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "            regress_var = fixed_regress\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                               \"|\",cluster,\"|\",\n",
    "                    paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data = data,alpha = alpha,maxdepth=maxdepth) \n",
    "            final_var = get_split_names(mytree$tree,data)\n",
    "            cat(\"There is only one module which is grey, final features\",final_var)\n",
    "        }else{\n",
    "            # at least one non-grey module\n",
    "            final_var = imp_var[[1]]\n",
    "            # if only one non-grey module: final_var is the chosen non-grey features\n",
    "            # if at least two non-grey modules:\n",
    "            if (length(imp_var)>1){\n",
    "                # There are at least 2 modules\n",
    "                for (i in 2:length(imp_var)){\n",
    "                final_var = c(final_var,imp_var[[i]])\n",
    "                }\n",
    "            \n",
    "            cat(\"After screening within non-grey modules\",final_var,\"\\n\")\n",
    "            # select from selected non-grey features\n",
    "            regress_var = fixed_regress\n",
    "            split_var = c(final_var,fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_select*length(split_var))\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                       \"|\",cluster,\"|\",\n",
    "                                     paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data = data,alpha = alpha,maxdepth=maxdepth) \n",
    "            final_var = get_split_names(mytree$tree,data)\n",
    "            }\n",
    "            cat(\"The chosen non-grey features are\",final_var,\"\\n\")\n",
    "            \n",
    "            # use final_var (chosen non-grey features) to select grey features\n",
    "            regress_var = c(fixed_regress,final_var)\n",
    "            split_var = c(module_dic[[\"grey\"]],fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                       \"|\",cluster,\"|\",\n",
    "                                     paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data = data,alpha = alpha,maxdepth=maxdepth) \n",
    "            grey_var = get_split_names(mytree$tree,data)\n",
    "            cat(\"The chosen grey features are\",grey_var,\"\\n\")\n",
    "            # use final_var and grey_var do to the final model tree\n",
    "            final_var = c(final_var,grey_var)    \n",
    "            cat(\"final features\",final_var)  \n",
    "        }\n",
    "        # use the final features as split&regression variables\n",
    "        split_var = c(final_var,fixed_split)\n",
    "        maxdepth = length(split_var)\n",
    "        regress_var = c(fixed_regress,final_var)\n",
    "        Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "        minsize = round(minsize_multiplier*length(regress_var))\n",
    "        mytree = lmertree(Formula, data = data,alpha=alpha,maxdepth=maxdepth,\n",
    "                         minsize=minsize) \n",
    "        mytree$final_selection = final_var\n",
    "        return(mytree)\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "# Methods for extracting names of splitting features used in a tree\n",
    "# tree: a tree object; data: the train or test set\n",
    "get_split_names = function(tree,data){\n",
    "    # path: the string that contains all the node information\n",
    "    paths <- pre:::list.rules(tree, removecomplements = FALSE)\n",
    "    vnames = names(data)\n",
    "    # the regex for a variable\n",
    "    # tomatch = paste(paste(var,\"<=\"),\"|\",paste(var,\">\"),sep=\"\")\n",
    "    # match to tomatch in path\n",
    "    tmp = vnames[sapply(sapply(vnames, FUN = function(var) grep(paste(paste(var,\"<=\"),\"|\",paste(var,\">\"),sep=\"\"), paths)), length) > 0]\n",
    "    return (tmp)\n",
    "}\n",
    "\n",
    "# Longtree_PC: used when fixed_regress are NULL, use PC as regressors for non-grey module\n",
    "# Longtree is equivalent to this Longtree_PC in this case\n",
    "Longtree_PC = function(data,fixed_split, var_select, power=power,cluster,\n",
    "                    alpha, maxdepth_factor_screen,maxdepth_factor_select,Fuzzy,\n",
    "                    minsize_multiplier){\n",
    "    # Cluster var_select\n",
    "    data_WGCNA = data[var_select]\n",
    "    # Must set numericLabels = FALSE so that it uses actual colors like \"grey\"\n",
    "    net = blockwiseModules(data_WGCNA, power = power,TOMType = \"unsigned\", \n",
    "                           minModuleSize = 30,reassignThreshold = 0, \n",
    "                           mergeCutHeight = 0.25,numericLabels = FALSE, \n",
    "                           pamRespectsDendro = FALSE,verbose = 0)\n",
    "    # the correspondance betweeen feature names and colors\n",
    "    colors = net$colors # it is a string vector with names (that is the name is V1)\n",
    "    module_names = unique(colors) # all color names\n",
    "    #\"dictionary\"with keys=name of color,values=names of features of that color\n",
    "    module_dic = list() \n",
    "    for (i in 1:length(module_names)){\n",
    "        module_dic[[module_names[i]]] = names(colors[colors==module_names[i]])\n",
    "    }\n",
    "    \n",
    "    # extract eigengenes and rename the column\n",
    "    # The eigengene(1st pricinpal component) is L2 normalized\n",
    "    eigengene = net$MEs\n",
    "    # eigengene\n",
    "    # add eigengen to training data (for grey group, eigengene is meaningless)\n",
    "    for (name in module_names){\n",
    "        if (name == \"grey\"){\n",
    "            next\n",
    "        }\n",
    "        eigen_name = paste(\"ME\",name,sep=\"\")\n",
    "        data[[eigen_name]] = eigengene[[eigen_name]]\n",
    "    }\n",
    "    imp_var = list() # used to store the names of important features\n",
    "    \n",
    "    if (Fuzzy==TRUE){\n",
    "        # first screen then select, just like Fuzzy Forest\n",
    "        # For each module that is not grey, use model tree as following:\n",
    "        # use its eigengene as regression variables and all features as splitting ones\n",
    "        # For grey module, use regular REEM (set regressor = \"1\")\n",
    "        # Then select by using all chosen features as split_var and regress=\"1\"\n",
    "        # Finally, use all the selected features for splitting and regression variables\n",
    "       \n",
    "        for (name in module_names){\n",
    "            split_var = c(module_dic[[name]],fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "            # use eigengene as regressor\n",
    "            if (name == \"grey\"){\n",
    "                regress_var = \"1\"\n",
    "            }else{\n",
    "                eigen_name = paste(\"ME\",name,sep=\"\")\n",
    "                regress_var = eigen_name\n",
    "            }\n",
    "            # Formula for lmtree: use PC as regressors\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "\n",
    "            # fit the tree\n",
    "            mytree = lmertree(Formula, data=data,alpha=alpha,maxdepth=maxdepth) \n",
    "            #extract important features\n",
    "            imp_var[[length(imp_var)+1]] = get_split_names(mytree$tree,data)\n",
    "        }        \n",
    "        # the variables selected from all the modules\n",
    "        final_var = imp_var[[1]]      \n",
    "        if (length(imp_var)>1){\n",
    "            for (i in 2:length(imp_var)){\n",
    "            final_var = c(final_var,imp_var[[i]])\n",
    "         }\n",
    "            cat(\"After screening within modules \",final_var,\"\\n\")\n",
    "            # select features again\n",
    "            # use all selected features as split_var with no regressors\n",
    "            split_var = c(final_var,fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_select*length(split_var))\n",
    "            Formula = as.formula(paste(\"y~\",\"1\",\n",
    "                                       \"|\",cluster,\"|\",\n",
    "                                     paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data = data,alpha=alpha,maxdepth=maxdepth)\n",
    "            final_var = get_split_names(mytree$tree,data)\n",
    "            cat(\"Final features \",final_var,\"\\n\")\n",
    "            \n",
    "        }else{\n",
    "            # length(imp_var) now is 1, only one module\n",
    "            cat(\"There is only one module \",final_var,\"\\n\")\n",
    "        }\n",
    "        \n",
    "        # use the final features as split&regression variables\n",
    "        split_var = c(final_var,fixed_split)\n",
    "        maxdepth = length(split_var)\n",
    "        Formula = as.formula(paste(\"y~\",paste(final_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "        minsize = round(minsize_multiplier*length(final_var))\n",
    "        mytree = lmertree(Formula, data = data,alpha=alpha,maxdepth=maxdepth,\n",
    "                         minsize = minsize)\n",
    "        mytree$final_selection = final_var\n",
    "        return (mytree)\n",
    "    }\n",
    "    \n",
    "    if (Fuzzy== FALSE){\n",
    "        # select features from non-grey modules and use them as regressors \n",
    "        # to select features from grey module. Then use all of them as split and regressor\n",
    "        \n",
    "        # for non-grey groups\n",
    "        for (name in module_names){\n",
    "            if (name == \"grey\"){\n",
    "                next\n",
    "            }\n",
    "            split_var = c(module_dic[[name]],fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "            # use eigengene as regressor\n",
    "            eigen_name = paste(\"ME\",name,sep=\"\")\n",
    "            regress_var = eigen_name\n",
    "            # Formula for lmtree: use PC as regressors\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "\n",
    "            # fit the tree\n",
    "            mytree = lmertree(Formula, data=data,alpha=alpha,maxdepth=maxdepth) \n",
    "            #extract important features\n",
    "            imp_var[[length(imp_var)+1]] = get_split_names(mytree$tree,data)\n",
    "        }\n",
    "        # Now imp_var contains all the non-grey screened features\n",
    "        if(length(imp_var)==0){\n",
    "            # there is only one module which is grey\n",
    "            # just select from the grey module\n",
    "            split_var = c(module_dic[[\"grey\"]],fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "            regress_var = \"1\"\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data=data,alpha=alpha,maxdepth=maxdepth) \n",
    "            final_var = get_split_names(mytree$tree,data)\n",
    "            cat(\"There is only grey module \",final_var,\"\\n\")\n",
    "        }\n",
    "        if(length(imp_var)==1){\n",
    "            # only one non-grey module\n",
    "            final_var = imp_var[[1]]\n",
    "            cat(\"There is only one non-grey module\",final_var,\"\\n\")\n",
    "            # use final_var as regressors\n",
    "            split_var = c(module_dic[[\"grey\"]],fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "            regress_var = final_var\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data=data,alpha=alpha,maxdepth=maxdepth) \n",
    "            grey_var = get_split_names(mytree$tree,data)\n",
    "            final_var = c(final_var,grey_var)\n",
    "            cat(\"The final features \",final_var,\"\\n\")\n",
    "        }\n",
    "        if(length(imp_var)>1){\n",
    "            # at least two non-grey modules, screen among non-grey modules\n",
    "            final_var = imp_var[[1]]\n",
    "            for (i in 2:length(imp_var)){\n",
    "                final_var = c(final_var,imp_var[[i]])\n",
    "                }\n",
    "            cat(\"After screening from non-grey modules \",final_var,\"\\n\")\n",
    "            # now final_var contains all the non-grey screened features\n",
    "            split_var = c(final_var,fixed_split)  \n",
    "            maxdepth = ceiling(maxdepth_factor_select*length(split_var))\n",
    "            regress_var = \"1\"\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data=data,alpha=alpha,maxdepth=maxdepth)\n",
    "            final_var = get_split_names(mytree$tree,data)\n",
    "            # Now final_var contains final non-grey features\n",
    "            cat(\"Final non-grey features \",final_var,\"\\n\")\n",
    "            # use final_var as regressors and select features from grey features\n",
    "            split_var = c(module_dic[[\"grey\"]],fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "            regress_var = final_var\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data=data,alpha=alpha,maxdepth=maxdepth) \n",
    "            grey_var = get_split_names(mytree$tree,data)\n",
    "            cat(\"Final grey features \",grey_var,\"\\n\")\n",
    "            final_var = c(final_var,grey_var)\n",
    "            cat(\"The final features \",final_var,\"\\n\")\n",
    "        }\n",
    "        # use the final features as split&regression variables\n",
    "        split_var = c(final_var,fixed_split)\n",
    "        maxdepth = length(split_var)\n",
    "        Formula = as.formula(paste(\"y~\",paste(final_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "        minsize = round(minsize_multiplier*length(final_var))\n",
    "        mytree = lmertree(Formula, data = data,alpha=alpha,maxdepth=maxdepth,\n",
    "                         minsize = minsize)\n",
    "        mytree$final_selection = final_var\n",
    "        return (mytree)\n",
    "    }\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Longtree = function(data,fixed_regress=NULL,fixed_split=NULL,var_select=NULL,\n",
    "                    power=6,cluster,maxdepth_factor_screen=0.04,\n",
    "                    maxdepth_factor_select=0.5,Fuzzy=TRUE,minsize_multiplier = 5,\n",
    "                    alpha_screen=0.2, alpha_select=0.2, alpha_predict=0.05){\n",
    "    ### if there are no features to select, just use fixed_regress and fixed_split\n",
    "    if(length(var_select)==0){\n",
    "        if (length(fixed_regress)==0){\n",
    "            if (length(fixed_split)==0){\n",
    "                stop(\"no features to split and regress on\")\n",
    "            }\n",
    "            fixed_regress = \"1\"\n",
    "        }\n",
    "        maxdepth = length(fixed_split)\n",
    "        Formula = as.formula(paste(\"y~\",paste(fixed_regress,collapse = \"+\"),\n",
    "                                       \"|\",cluster,\"|\",\n",
    "                                     paste(fixed_split,collapse = \"+\")))\n",
    "        mytree = lmertree(Formula,data=data,alpha=alpha_predict,maxdepth=maxdepth)\n",
    "        mytree$final_selection = NULL\n",
    "        return (mytree)\n",
    "    } ###\n",
    "    # Now var_select is not empty\n",
    "    # If don't specify fixed_regress: use PC as regressors at screening step\n",
    "    if (length(fixed_regress)==0){\n",
    "        cat(\"Use Longtree_PC\\n\")\n",
    "        return(Longtree_PC(data=data,fixed_split=fixed_split,\n",
    "                    var_select=var_select,\n",
    "                    power=power,cluster=cluster,\n",
    "                    maxdepth_factor_screen=maxdepth_factor_screen, \n",
    "                    maxdepth_factor_select=maxdepth_factor_select,Fuzzy=Fuzzy,\n",
    "                    minsize_multiplier=minsize_multiplier,\n",
    "                    alpha_screen=alpha_screen, alpha_select=alpha_select, \n",
    "                    alpha_predict=alpha_predict))\n",
    "    }###\n",
    "    # Now we have non-empty var_select,fixed_regress\n",
    "    cat(\"Use Longtree_time\\n\")\n",
    "    return(Longtree_time(data=data,fixed_regress=fixed_regress,\n",
    "                        fixed_split=fixed_split, var_select=var_select,\n",
    "                    power=power,cluster=cluster,\n",
    "                    maxdepth_factor_screen=maxdepth_factor_screen, \n",
    "                    maxdepth_factor_select=maxdepth_factor_select,Fuzzy=Fuzzy,\n",
    "                    minsize_multiplier=minsize_multiplier,\n",
    "                    alpha_screen=alpha_screen, alpha_select=alpha_select, \n",
    "                    alpha_predict=alpha_predict))\n",
    "                        \n",
    "}\n",
    "\n",
    "# Longtree_time: used when var_select and fixed_regress are non-empty\n",
    "# Longtree is equivalent to this Longtree_time in this case\n",
    "Longtree_time = function(data,fixed_regress,fixed_split,var_select,power,cluster,\n",
    "                         maxdepth_factor_screen,maxdepth_factor_select,\n",
    "                         Fuzzy,minsize_multiplier,alpha_screen,alpha_select,\n",
    "                         alpha_predict){\n",
    "    # Cluster var_select\n",
    "    data_WGCNA = data[var_select]\n",
    "    # Must set numericLabels = FALSE so that it uses actual colors like \"grey\"\n",
    "    net = blockwiseModules(data_WGCNA, power = power,TOMType = \"unsigned\", \n",
    "                           minModuleSize = 30,reassignThreshold = 0, \n",
    "                           mergeCutHeight = 0.25,numericLabels = FALSE, \n",
    "                           pamRespectsDendro = FALSE,verbose = 0)\n",
    "    # the correspondance betweeen feature names and colors\n",
    "    colors = net$colors # it is a string vector with names (that is the name is V1)\n",
    "    module_names = unique(colors) # all color names\n",
    "    #\"dictionary\"with keys=name of color,values=names of features of that color\n",
    "    module_dic = list() \n",
    "    for (i in 1:length(module_names)){\n",
    "        module_dic[[module_names[i]]] = names(colors[colors==module_names[i]])\n",
    "    }\n",
    "    \n",
    "    imp_var = list() # used to store the names of important features\n",
    "    \n",
    "    if(Fuzzy==TRUE){\n",
    "        # Do the selection step just like Fuzzy Forest:\n",
    "        # for each module (including grey), use them as split_var and select\n",
    "        # finally, use all selected ones as split_var and select\n",
    "        \n",
    "        for (name in module_names){\n",
    "        # in the formula, add fixed_split as split_var, also include the module features\n",
    "        split_var = c(module_dic[[name]],fixed_split)\n",
    "        maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "        # use fixed_regress as regressor\n",
    "        regress_var = fixed_regress\n",
    "\n",
    "        # Formula for lmtree\n",
    "        Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                               \"|\",cluster,\"|\",\n",
    "                    paste(split_var,collapse = \"+\")))\n",
    "\n",
    "        # fit the tree\n",
    "        mytree = lmertree(Formula, data = data,alpha=alpha_screen,maxdepth=maxdepth) \n",
    "\n",
    "        #extract important features\n",
    "        imp_var[[length(imp_var)+1]] = get_split_names(mytree$tree,data)\n",
    "        }\n",
    "        \n",
    "        # the variables selected from all the modules\n",
    "        final_var = imp_var[[1]]\n",
    "        if (length(imp_var)>1){\n",
    "            # There are at least 2 modules\n",
    "            for (i in 2:length(imp_var)){\n",
    "            final_var = c(final_var,imp_var[[i]])\n",
    "         }\n",
    "            cat(\"after screening within modules\",final_var,\"\\n\")\n",
    "            \n",
    "            # the final selection among all the chosen features \n",
    "            regress_var = fixed_regress\n",
    "            split_var = c(final_var,fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_select*length(split_var))\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                       \"|\",cluster,\"|\",\n",
    "                                     paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data = data,alpha=alpha_select,maxdepth=maxdepth) \n",
    "            final_var = get_split_names(mytree$tree,data)\n",
    "            cat(\"final features\",final_var)      \n",
    "        }else{\n",
    "            # only grey module\n",
    "            cat(\"There is only one module, final features\",final_var)\n",
    "        }\n",
    "        # use the final features as split&regression variables\n",
    "        split_var = c(final_var,fixed_split)\n",
    "        maxdepth = length(split_var)\n",
    "        regress_var = c(fixed_regress,final_var)\n",
    "        Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "        minsize = round(minsize_multiplier*length(regress_var))\n",
    "        mytree = lmertree(Formula, data = data,alpha=alpha_predict,maxdepth=maxdepth,\n",
    "                         minsize = minsize)\n",
    "        mytree$final_selection = final_var\n",
    "        return(mytree)           \n",
    "    }\n",
    "    if(Fuzzy==FALSE){\n",
    "        # first do the screening and selecting in non-grey modules\n",
    "        # Then use those non-grey estimated true features as regressors\n",
    "        # and grey features as split_var, choose grey features and keep them\n",
    "        for (name in module_names){\n",
    "        if(name==\"grey\"){\n",
    "            next\n",
    "        }\n",
    "        split_var = c(module_dic[[name]],fixed_split)\n",
    "        maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "        regress_var = fixed_regress\n",
    "\n",
    "        # Formula for lmtree\n",
    "        Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                               \"|\",cluster,\"|\",\n",
    "                    paste(split_var,collapse = \"+\")))\n",
    "\n",
    "        # fit the tree\n",
    "        mytree = lmertree(Formula, data = data,alpha=alpha_screen,maxdepth=maxdepth) \n",
    "\n",
    "        #extract important features\n",
    "        imp_var[[length(imp_var)+1]] = get_split_names(mytree$tree,data)\n",
    "        }# Now imp_var contains important features from modules that are not grey\n",
    "        if(length(imp_var)==0){\n",
    "            # only grey module, no other modules\n",
    "            split_var = c(module_dic[[\"grey\"]],fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "            regress_var = fixed_regress\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                               \"|\",cluster,\"|\",\n",
    "                    paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data = data,alpha = alpha_screen,maxdepth=maxdepth) \n",
    "            final_var = get_split_names(mytree$tree,data)\n",
    "            cat(\"There is only one module which is grey, final features\",final_var)\n",
    "        }else{\n",
    "            # at least one non-grey module\n",
    "            final_var = imp_var[[1]]\n",
    "            # if only one non-grey module: final_var is the chosen non-grey features\n",
    "            # if at least two non-grey modules:\n",
    "            if (length(imp_var)>1){\n",
    "                # There are at least 2 modules\n",
    "                for (i in 2:length(imp_var)){\n",
    "                final_var = c(final_var,imp_var[[i]])\n",
    "                }\n",
    "            \n",
    "            cat(\"After screening within non-grey modules\",final_var,\"\\n\")\n",
    "            # select from selected non-grey features\n",
    "            regress_var = fixed_regress\n",
    "            split_var = c(final_var,fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_select*length(split_var))\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                       \"|\",cluster,\"|\",\n",
    "                                     paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data = data,alpha = alpha_select,maxdepth=maxdepth) \n",
    "            final_var = get_split_names(mytree$tree,data)\n",
    "            }\n",
    "            cat(\"The chosen non-grey features are\",final_var,\"\\n\")\n",
    "            \n",
    "            # use final_var (chosen non-grey features) to select grey features\n",
    "            regress_var = c(fixed_regress,final_var)\n",
    "            split_var = c(module_dic[[\"grey\"]],fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                       \"|\",cluster,\"|\",\n",
    "                                     paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data = data,alpha = alpha_screen,maxdepth=maxdepth) \n",
    "            grey_var = get_split_names(mytree$tree,data)\n",
    "            cat(\"The chosen grey features are\",grey_var,\"\\n\")\n",
    "            # use final_var and grey_var do to the final model tree\n",
    "            final_var = c(final_var,grey_var)    \n",
    "            cat(\"final features\",final_var)  \n",
    "        }\n",
    "        # use the final features as split&regression variables\n",
    "        split_var = c(final_var,fixed_split)\n",
    "        maxdepth = length(split_var)\n",
    "        regress_var = c(fixed_regress,final_var)\n",
    "        Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "        minsize = round(minsize_multiplier*length(regress_var))\n",
    "        mytree = lmertree(Formula, data = data,alpha=alpha_predict,maxdepth=maxdepth,\n",
    "                         minsize=minsize) \n",
    "        mytree$final_selection = final_var\n",
    "        return(mytree)\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "# Methods for extracting names of splitting features used in a tree\n",
    "# tree: a tree object; data: the train or test set\n",
    "get_split_names = function(tree,data){\n",
    "    # path: the string that contains all the node information\n",
    "    paths <- pre:::list.rules(tree, removecomplements = FALSE)\n",
    "    vnames = names(data)\n",
    "    # the regex for a variable\n",
    "    # tomatch = paste(paste(var,\"<=\"),\"|\",paste(var,\">\"),sep=\"\")\n",
    "    # match to tomatch in path\n",
    "    tmp = vnames[sapply(sapply(vnames, FUN = function(var) grep(paste(paste(var,\"<=\"),\"|\",paste(var,\">\"),sep=\"\"), paths)), length) > 0]\n",
    "    return (tmp)\n",
    "}\n",
    "\n",
    "# Longtree_PC: used when fixed_regress are NULL, use PC as regressors for non-grey module\n",
    "# Longtree is equivalent to this Longtree_PC in this case\n",
    "Longtree_PC = function(data,fixed_split, var_select, power,cluster,\n",
    "                    maxdepth_factor_screen,maxdepth_factor_select,Fuzzy,\n",
    "                    minsize_multiplier,alpha_screen,alpha_select,\n",
    "                    alpha_predict){\n",
    "    # Cluster var_select\n",
    "    data_WGCNA = data[var_select]\n",
    "    # Must set numericLabels = FALSE so that it uses actual colors like \"grey\"\n",
    "    net = blockwiseModules(data_WGCNA, power = power,TOMType = \"unsigned\", \n",
    "                           minModuleSize = 30,reassignThreshold = 0, \n",
    "                           mergeCutHeight = 0.25,numericLabels = FALSE, \n",
    "                           pamRespectsDendro = FALSE,verbose = 0)\n",
    "    # the correspondance betweeen feature names and colors\n",
    "    colors = net$colors # it is a string vector with names (that is the name is V1)\n",
    "    module_names = unique(colors) # all color names\n",
    "    #\"dictionary\"with keys=name of color,values=names of features of that color\n",
    "    module_dic = list() \n",
    "    for (i in 1:length(module_names)){\n",
    "        module_dic[[module_names[i]]] = names(colors[colors==module_names[i]])\n",
    "    }\n",
    "    \n",
    "    # extract eigengenes and rename the column\n",
    "    # The eigengene(1st pricinpal component) is L2 normalized\n",
    "    eigengene = net$MEs\n",
    "    # eigengene\n",
    "    # add eigengen to training data (for grey group, eigengene is meaningless)\n",
    "    for (name in module_names){\n",
    "        if (name == \"grey\"){\n",
    "            next\n",
    "        }\n",
    "        eigen_name = paste(\"ME\",name,sep=\"\")\n",
    "        data[[eigen_name]] = eigengene[[eigen_name]]\n",
    "    }\n",
    "    imp_var = list() # used to store the names of important features\n",
    "    \n",
    "    if (Fuzzy==TRUE){\n",
    "        # first screen then select, just like Fuzzy Forest\n",
    "        # For each module that is not grey, use model tree as following:\n",
    "        # use its eigengene as regression variables and all features as splitting ones\n",
    "        # For grey module, use regular REEM (set regressor = \"1\")\n",
    "        # Then select by using all chosen features as split_var and regress=\"1\"\n",
    "        # Finally, use all the selected features for splitting and regression variables\n",
    "       \n",
    "        for (name in module_names){\n",
    "            split_var = c(module_dic[[name]],fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "            # use eigengene as regressor\n",
    "            if (name == \"grey\"){\n",
    "                regress_var = \"1\"\n",
    "            }else{\n",
    "                eigen_name = paste(\"ME\",name,sep=\"\")\n",
    "                regress_var = eigen_name\n",
    "            }\n",
    "            # Formula for lmtree: use PC as regressors\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "\n",
    "            # fit the tree\n",
    "            mytree = lmertree(Formula, data=data,alpha=alpha_screen,maxdepth=maxdepth) \n",
    "            #extract important features\n",
    "            imp_var[[length(imp_var)+1]] = get_split_names(mytree$tree,data)\n",
    "        }        \n",
    "        # the variables selected from all the modules\n",
    "        final_var = imp_var[[1]]      \n",
    "        if (length(imp_var)>1){\n",
    "            for (i in 2:length(imp_var)){\n",
    "            final_var = c(final_var,imp_var[[i]])\n",
    "         }\n",
    "            cat(\"After screening within modules \",final_var,\"\\n\")\n",
    "            # select features again\n",
    "            # use all selected features as split_var with no regressors\n",
    "            split_var = c(final_var,fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_select*length(split_var))\n",
    "            Formula = as.formula(paste(\"y~\",\"1\",\n",
    "                                       \"|\",cluster,\"|\",\n",
    "                                     paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data = data,alpha=alpha_select,maxdepth=maxdepth)\n",
    "            final_var = get_split_names(mytree$tree,data)\n",
    "            cat(\"Final features \",final_var,\"\\n\")\n",
    "            \n",
    "        }else{\n",
    "            # length(imp_var) now is 1, only one module\n",
    "            cat(\"There is only one module \",final_var,\"\\n\")\n",
    "        }\n",
    "        \n",
    "        # use the final features as split&regression variables\n",
    "        split_var = c(final_var,fixed_split)\n",
    "        maxdepth = length(split_var)\n",
    "        Formula = as.formula(paste(\"y~\",paste(final_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "        minsize = round(minsize_multiplier*length(final_var))\n",
    "        mytree = lmertree(Formula, data = data,alpha=alpha_predict,maxdepth=maxdepth,\n",
    "                         minsize = minsize)\n",
    "        mytree$final_selection = final_var\n",
    "        return (mytree)\n",
    "    }\n",
    "    \n",
    "    if (Fuzzy== FALSE){\n",
    "        # select features from non-grey modules and use them as regressors \n",
    "        # to select features from grey module. Then use all of them as split and regressor\n",
    "        \n",
    "        # for non-grey groups\n",
    "        for (name in module_names){\n",
    "            if (name == \"grey\"){\n",
    "                next\n",
    "            }\n",
    "            split_var = c(module_dic[[name]],fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "            # use eigengene as regressor\n",
    "            eigen_name = paste(\"ME\",name,sep=\"\")\n",
    "            regress_var = eigen_name\n",
    "            # Formula for lmtree: use PC as regressors\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "\n",
    "            # fit the tree\n",
    "            mytree = lmertree(Formula, data=data,alpha=alpha_screen,maxdepth=maxdepth) \n",
    "            #extract important features\n",
    "            imp_var[[length(imp_var)+1]] = get_split_names(mytree$tree,data)\n",
    "        }\n",
    "        # Now imp_var contains all the non-grey screened features\n",
    "        if(length(imp_var)==0){\n",
    "            # there is only one module which is grey\n",
    "            # just select from the grey module\n",
    "            split_var = c(module_dic[[\"grey\"]],fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "            regress_var = \"1\"\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data=data,alpha=alpha_screen,maxdepth=maxdepth) \n",
    "            final_var = get_split_names(mytree$tree,data)\n",
    "            cat(\"There is only grey module \",final_var,\"\\n\")\n",
    "        }\n",
    "        if(length(imp_var)==1){\n",
    "            # only one non-grey module\n",
    "            final_var = imp_var[[1]]\n",
    "            cat(\"There is only one non-grey module\",final_var,\"\\n\")\n",
    "            # use final_var as regressors\n",
    "            split_var = c(module_dic[[\"grey\"]],fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "            regress_var = final_var\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data=data,alpha=alpha_screen,maxdepth=maxdepth) \n",
    "            grey_var = get_split_names(mytree$tree,data)\n",
    "            final_var = c(final_var,grey_var)\n",
    "            cat(\"The final features \",final_var,\"\\n\")\n",
    "        }\n",
    "        if(length(imp_var)>1){\n",
    "            # at least two non-grey modules, select among non-grey modules\n",
    "            final_var = imp_var[[1]]\n",
    "            for (i in 2:length(imp_var)){\n",
    "                final_var = c(final_var,imp_var[[i]])\n",
    "                }\n",
    "            cat(\"After screening from non-grey modules \",final_var,\"\\n\")\n",
    "            # now final_var contains all the non-grey screened features\n",
    "            split_var = c(final_var,fixed_split)  \n",
    "            maxdepth = ceiling(maxdepth_factor_select*length(split_var))\n",
    "            regress_var = \"1\"\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data=data,alpha=alpha_select,maxdepth=maxdepth)\n",
    "            final_var = get_split_names(mytree$tree,data)\n",
    "            # Now final_var contains final non-grey features\n",
    "            cat(\"Final non-grey features \",final_var,\"\\n\")\n",
    "            # use final_var as regressors and select features from grey features\n",
    "            split_var = c(module_dic[[\"grey\"]],fixed_split)\n",
    "            maxdepth = ceiling(maxdepth_factor_screen*length(split_var))\n",
    "            regress_var = final_var\n",
    "            Formula = as.formula(paste(\"y~\",paste(regress_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "            mytree = lmertree(Formula, data=data,alpha=alpha_screen,maxdepth=maxdepth) \n",
    "            grey_var = get_split_names(mytree$tree,data)\n",
    "            cat(\"Final grey features \",grey_var,\"\\n\")\n",
    "            final_var = c(final_var,grey_var)\n",
    "            cat(\"The final features \",final_var,\"\\n\")\n",
    "        }\n",
    "        # use the final features as split&regression variables\n",
    "        split_var = c(final_var,fixed_split)\n",
    "        maxdepth = length(split_var)\n",
    "        Formula = as.formula(paste(\"y~\",paste(final_var,collapse = \"+\"),\n",
    "                                   \"|\",cluster,\"|\",\n",
    "                                 paste(split_var,collapse = \"+\")))\n",
    "        minsize = round(minsize_multiplier*length(final_var))\n",
    "        mytree = lmertree(Formula, data = data,alpha=alpha_predict,maxdepth=maxdepth,\n",
    "                         minsize = minsize)\n",
    "        mytree$final_selection = final_var\n",
    "        return (mytree)\n",
    "    }\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longtree_PC Sample Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in sim_3(n, T): could not find function \"sim_3\"\n",
     "output_type": "error",
     "traceback": [
      "Error in sim_3(n, T): could not find function \"sim_3\"\nTraceback:\n",
      "1. as.data.frame(sim_3(n, T))"
     ]
    }
   ],
   "source": [
    "n <- 1000 # number of patients\n",
    "T <-  5 # number of observations per patients\n",
    "set.seed(100)\n",
    "\n",
    "data <- as.data.frame(sim_3(n, T)) \n",
    "colnames(data)[401] <- \"y\"\n",
    "for (i in 1:n){\n",
    "    data$patient[(1+(i-1)*T):(i*T)] = rep(i,T)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test <- 100 \n",
    "T <-  5 \n",
    "set.seed(101)\n",
    "data_test <- as.data.frame(sim_3(n_test, T)) \n",
    "colnames(data_test)[401] <- \"y\"\n",
    "for (i in 1:n_test){\n",
    "    data_test$patient[(1+(i-1)*T):(i*T)] = rep(i,T)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = \"patient\"\n",
    "fixed_regress = NULL\n",
    "fixed_split = NULL\n",
    "var_select = paste(\"V\",1:400,sep=\"\")\n",
    "# fixed_split = \"V303\"\n",
    "# var_select = paste(\"V\",setdiff(1:400,303),sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Longtree_PC\n",
      "After screening from non-grey modules  V1 V2 V3 V141 V150 \n",
      "Final non-grey features  V1 V2 V3 \n",
      "Final grey features  V301 V302 V303 \n",
      "The final features  V1 V2 V3 V301 V302 V303 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       " 162.48    1.25  174.78 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "5.21211513825921"
      ],
      "text/latex": [
       "5.21211513825921"
      ],
      "text/markdown": [
       "5.21211513825921"
      ],
      "text/plain": [
       "[1] 5.212115"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system.time({\n",
    "    mytree = Longtree(data,fixed_regress=fixed_regress,fixed_split=fixed_split,\n",
    "                  var_select=var_select,cluster=cluster,Fuzzy=FALSE)\n",
    "})\n",
    "mean((predict(mytree,newdata=data_test,re.form=NA)-data_test$y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longtree_time: Sample Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "n <- 1000 # number of patients\n",
    "T <-  5 # number of observations per patients\n",
    "\n",
    "set.seed(100)\n",
    "\n",
    "data <- sim_quad(n,T,a1=1,a2=-1)\n",
    "# add time_squared\n",
    "data$time2 = (data$time)^2\n",
    "\n",
    "# testing data\n",
    "n_test <- 100 # number of patients\n",
    "T <-  5 # number of observations per patients\n",
    "set.seed(101)\n",
    "data_test <- sim_quad(n_test,T,a1=1,a2=-1)\n",
    "# data_test <- sim_quad(n_test, T)\n",
    "data_test$time2 = (data_test$time)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_regress = c(\"time\",\"time2\")\n",
    "fixed_split = c(\"treatment\")\n",
    "cluster = \"patient\"\n",
    "var_select = paste(\"V\",1:400,sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Longtree_time\n",
      "after screening within modules V1 V2 V3 V45 V301 V302 V303 V365 \n",
      "final features V1 V2 V3 V45 V301 V302 V303"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       " 284.23    4.03  291.34 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3.94589320497893"
      ],
      "text/latex": [
       "3.94589320497893"
      ],
      "text/markdown": [
       "3.94589320497893"
      ],
      "text/plain": [
       "[1] 3.945893"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>(Intercept)</th><th scope=col>time</th><th scope=col>time2</th><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V45</th><th scope=col>V301</th><th scope=col>V302</th><th scope=col>V303</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>7</th><td> -6.349571  </td><td>-7.350222   </td><td> 1.2114900  </td><td>4.171255    </td><td> -6.8839144 </td><td> -7.3718101 </td><td> 1.541683559</td><td>4.494505    </td><td>-0.7512000  </td><td>-3.9651174  </td></tr>\n",
       "\t<tr><th scope=row>8</th><td> -3.658046  </td><td>-6.883360   </td><td> 1.1881768  </td><td>5.108242    </td><td> -7.1688688 </td><td> -5.0943271 </td><td> 0.057436244</td><td>4.526475    </td><td>-2.8828999  </td><td> 0.9714997  </td></tr>\n",
       "\t<tr><th scope=row>9</th><td> -3.698400  </td><td>-5.602412   </td><td> 0.9491308  </td><td>5.115616    </td><td> -8.6631469 </td><td> -4.8501337 </td><td>-0.564776744</td><td>5.377504    </td><td>-1.5535279  </td><td> 6.3739251  </td></tr>\n",
       "\t<tr><th scope=row>12</th><td>  2.665192  </td><td>-4.347118   </td><td> 0.7527754  </td><td>5.103950    </td><td> -1.2328158 </td><td>  1.2561532 </td><td>-0.003304848</td><td>4.863811    </td><td>-1.4622593  </td><td>-3.7378360  </td></tr>\n",
       "\t<tr><th scope=row>14</th><td>  6.238134  </td><td>-6.017547   </td><td> 1.0210227  </td><td>5.133300    </td><td> -1.7202024 </td><td> -0.8393982 </td><td> 0.049126577</td><td>5.055169    </td><td>-1.9300952  </td><td> 0.5422217  </td></tr>\n",
       "\t<tr><th scope=row>15</th><td>  8.367578  </td><td>-5.629857   </td><td> 0.9427324  </td><td>4.275650    </td><td> -1.0969766 </td><td> -0.2755758 </td><td> 0.054170399</td><td>4.870142    </td><td>-2.1582460  </td><td> 3.5697818  </td></tr>\n",
       "\t<tr><th scope=row>16</th><td> 14.394620  </td><td>-6.824156   </td><td> 1.1617445  </td><td>5.539400    </td><td> -1.7106410 </td><td> -0.9579946 </td><td> 0.793770034</td><td>5.224937    </td><td>-2.4107370  </td><td> 8.8672637  </td></tr>\n",
       "\t<tr><th scope=row>19</th><td>-19.405325  </td><td> 4.318409   </td><td>-0.7500138  </td><td>4.424966    </td><td> -6.7462368 </td><td> -6.0823057 </td><td> 1.608117424</td><td>5.017769    </td><td>-4.8821657  </td><td> 1.5511117  </td></tr>\n",
       "\t<tr><th scope=row>21</th><td> -6.724431  </td><td> 4.362079   </td><td>-0.7458413  </td><td>5.397429    </td><td> -0.8061076 </td><td> -0.7187922 </td><td>-0.296876866</td><td>5.236399    </td><td>-7.0547208  </td><td> 2.7592528  </td></tr>\n",
       "\t<tr><th scope=row>22</th><td>-12.449150  </td><td> 5.888207   </td><td>-0.9973595  </td><td>5.003771    </td><td> -0.4268434 </td><td> -0.5087410 </td><td> 0.239971645</td><td>5.043480    </td><td>-3.7509750  </td><td>-0.5490829  </td></tr>\n",
       "\t<tr><th scope=row>24</th><td>-22.044653  </td><td> 5.433242   </td><td>-0.9644557  </td><td>5.271411    </td><td> -7.5937295 </td><td> -6.5730112 </td><td>-0.004060539</td><td>4.753809    </td><td>-0.1891438  </td><td> 3.9123291  </td></tr>\n",
       "\t<tr><th scope=row>27</th><td>-13.551162  </td><td> 5.966522   </td><td>-0.9868972  </td><td>5.307705    </td><td> -1.2932211 </td><td> -3.0401245 </td><td> 0.670361864</td><td>5.176984    </td><td> 0.4277795  </td><td>-3.2960232  </td></tr>\n",
       "\t<tr><th scope=row>28</th><td>-10.729902  </td><td> 5.259813   </td><td>-0.8753016  </td><td>5.043273    </td><td> -0.2440885 </td><td>  0.1731477 </td><td>-0.017660917</td><td>5.015934    </td><td>-0.2169641  </td><td>-2.2637621  </td></tr>\n",
       "\t<tr><th scope=row>30</th><td>-11.381880  </td><td> 7.176069   </td><td>-1.2332314  </td><td>5.013619    </td><td> -2.5695674 </td><td> -1.1848845 </td><td>-0.026636250</td><td>5.171960    </td><td> 0.4868277  </td><td> 6.1654098  </td></tr>\n",
       "\t<tr><th scope=row>31</th><td> -8.662221  </td><td> 6.363031   </td><td>-1.0785895  </td><td>5.292586    </td><td>  0.1361963 </td><td> -0.9962916 </td><td>-0.254812035</td><td>5.154156    </td><td>-0.1956774  </td><td> 6.0314359  </td></tr>\n",
       "\t<tr><th scope=row>35</th><td>-13.094860  </td><td>-7.752458   </td><td> 1.3391086  </td><td>5.518346    </td><td> -8.4232009 </td><td>-10.1897569 </td><td> 0.138806683</td><td>4.839941    </td><td> 5.0147350  </td><td> 2.6823288  </td></tr>\n",
       "\t<tr><th scope=row>38</th><td>  4.807691  </td><td>-5.717462   </td><td> 0.9773386  </td><td>5.737535    </td><td> -3.9051448 </td><td> -3.0201751 </td><td> 0.120116130</td><td>4.830966    </td><td> 3.7825144  </td><td>-2.2656989  </td></tr>\n",
       "\t<tr><th scope=row>39</th><td> 12.448217  </td><td>-6.292740   </td><td> 1.0637098  </td><td>5.085854    </td><td> -0.3409647 </td><td>  2.4920219 </td><td>-0.264151860</td><td>4.869839    </td><td> 5.1598990  </td><td>-3.0776316  </td></tr>\n",
       "\t<tr><th scope=row>41</th><td>  3.056057  </td><td>-6.231778   </td><td> 1.0580689  </td><td>5.183706    </td><td> -2.2687426 </td><td> -2.9811756 </td><td>-0.178488353</td><td>5.046729    </td><td> 4.0875275  </td><td> 6.6090887  </td></tr>\n",
       "\t<tr><th scope=row>42</th><td>  6.326519  </td><td>-5.409271   </td><td> 0.8787784  </td><td>5.116082    </td><td> -0.7725164 </td><td>  1.1414081 </td><td> 0.055282944</td><td>4.930518    </td><td> 5.0164417  </td><td> 5.4241915  </td></tr>\n",
       "\t<tr><th scope=row>45</th><td>  7.819880  </td><td>-5.599724   </td><td> 0.9485516  </td><td>5.194656    </td><td> -6.0792588 </td><td> -4.5591638 </td><td> 0.631989217</td><td>5.364900    </td><td> 9.2924404  </td><td>-3.9618229  </td></tr>\n",
       "\t<tr><th scope=row>46</th><td>  9.164637  </td><td>-5.106353   </td><td> 0.8393423  </td><td>4.752908    </td><td>  0.3195804 </td><td> -1.7855249 </td><td>-0.481749671</td><td>4.975436    </td><td> 9.6274354  </td><td> 0.1891514  </td></tr>\n",
       "\t<tr><th scope=row>47</th><td> -1.259075  </td><td>-7.996618   </td><td> 1.3466470  </td><td>5.154770    </td><td> -2.8082342 </td><td> -2.5625405 </td><td> 0.470185985</td><td>4.774474    </td><td>11.4824890  </td><td> 7.0828526  </td></tr>\n",
       "\t<tr><th scope=row>50</th><td>-21.912377  </td><td> 5.522484   </td><td>-0.9458886  </td><td>4.965381    </td><td> -6.1067589 </td><td> -6.3365888 </td><td>-0.439651222</td><td>5.338519    </td><td> 4.0930690  </td><td> 1.8931533  </td></tr>\n",
       "\t<tr><th scope=row>51</th><td>-27.836367  </td><td> 3.847604   </td><td>-0.6521752  </td><td>4.444572    </td><td>-10.0806880 </td><td> -8.1897339 </td><td> 2.273282076</td><td>5.185005    </td><td> 9.3469075  </td><td> 3.1153888  </td></tr>\n",
       "\t<tr><th scope=row>55</th><td> -8.001267  </td><td> 5.198383   </td><td>-0.8909435  </td><td>5.753566    </td><td> -1.3352775 </td><td> -1.3551278 </td><td>-0.321050987</td><td>5.657438    </td><td> 3.4537616  </td><td>-5.2260658  </td></tr>\n",
       "\t<tr><th scope=row>56</th><td> -9.752904  </td><td> 5.893257   </td><td>-0.9540705  </td><td>4.877735    </td><td> -0.4143296 </td><td> -1.6038974 </td><td>-0.167759645</td><td>5.296625    </td><td> 4.5660443  </td><td>-0.4736331  </td></tr>\n",
       "\t<tr><th scope=row>58</th><td>-14.609936  </td><td> 6.127920   </td><td>-1.0328064  </td><td>4.946224    </td><td> -3.7773419 </td><td> -1.5659736 </td><td> 0.213128245</td><td>4.984605    </td><td> 4.7634567  </td><td> 5.3403539  </td></tr>\n",
       "\t<tr><th scope=row>59</th><td>-10.365922  </td><td> 5.686339   </td><td>-0.9591345  </td><td>5.020290    </td><td> -0.1211690 </td><td>  0.8767491 </td><td>-0.082980068</td><td>4.802946    </td><td> 5.1490904  </td><td> 4.4722205  </td></tr>\n",
       "\t<tr><th scope=row>61</th><td> -9.751992  </td><td> 5.489350   </td><td>-0.9272415  </td><td>4.138274    </td><td> -1.7790765 </td><td> -0.2289724 </td><td> 0.456656967</td><td>5.154154    </td><td> 8.7488899  </td><td> 1.9197987  </td></tr>\n",
       "\t<tr><th scope=row>...</th><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><th scope=row>87</th><td>-15.7689421</td><td> 4.524557  </td><td>-0.7310722 </td><td>5.365526   </td><td> 3.822468  </td><td> 4.190592  </td><td>-0.70645722</td><td>4.845132   </td><td>-3.4498033 </td><td>-5.5562817 </td></tr>\n",
       "\t<tr><th scope=row>88</th><td>-11.8596058</td><td> 5.966243  </td><td>-1.0022988 </td><td>5.357427   </td><td> 3.409241  </td><td> 2.994849  </td><td> 0.13689597</td><td>4.988578   </td><td>-3.0599572 </td><td>-0.7054587 </td></tr>\n",
       "\t<tr><th scope=row>91</th><td> -5.2930163</td><td> 5.474512  </td><td>-0.9384664 </td><td>4.970255   </td><td> 3.963720  </td><td> 2.577223  </td><td>-0.07005220</td><td>4.927862   </td><td> 4.1547767 </td><td>-4.0691930 </td></tr>\n",
       "\t<tr><th scope=row>92</th><td> -6.8224427</td><td> 5.187634  </td><td>-0.8530157 </td><td>4.674332   </td><td> 3.429878  </td><td> 3.530035  </td><td>-0.06011514</td><td>5.018971   </td><td> 5.1743709 </td><td>-0.4107791 </td></tr>\n",
       "\t<tr><th scope=row>93</th><td> -0.2213838</td><td> 5.242802  </td><td>-0.8525191 </td><td>4.917581   </td><td> 4.078965  </td><td> 2.332487  </td><td> 0.36268627</td><td>5.290928   </td><td> 9.5074379 </td><td>-3.3375099 </td></tr>\n",
       "\t<tr><th scope=row>96</th><td>-10.8692317</td><td> 4.588524  </td><td>-0.7802483 </td><td>5.383366   </td><td> 5.404228  </td><td> 8.552615  </td><td> 0.74589154</td><td>4.611610   </td><td> 3.2153187 </td><td>-4.5617277 </td></tr>\n",
       "\t<tr><th scope=row>97</th><td>-24.7509425</td><td> 5.572279  </td><td>-1.0431289 </td><td>4.475659   </td><td> 8.251356  </td><td>10.303484  </td><td> 2.46279933</td><td>4.531958   </td><td>-1.2509979 </td><td>-5.4946947 </td></tr>\n",
       "\t<tr><th scope=row>99</th><td>-18.7608026</td><td> 4.871280  </td><td>-0.8348056 </td><td>4.907792   </td><td> 8.795497  </td><td> 9.763008  </td><td> 0.05920735</td><td>5.383504   </td><td>-1.7514458 </td><td>-0.2796193 </td></tr>\n",
       "\t<tr><th scope=row>100</th><td>-16.6772449</td><td> 6.482455  </td><td>-1.0548595 </td><td>4.781487   </td><td> 9.013663  </td><td> 9.151572  </td><td>-0.12029910</td><td>4.716647   </td><td> 7.2613030 </td><td>-0.1448964 </td></tr>\n",
       "\t<tr><th scope=row>106</th><td>  9.3941321</td><td>-5.884971  </td><td> 0.9764701 </td><td>4.551538   </td><td> 2.963078  </td><td> 3.341592  </td><td> 0.32235186</td><td>5.065561   </td><td>-0.9709176 </td><td> 3.0570445 </td></tr>\n",
       "\t<tr><th scope=row>107</th><td>  6.9809196</td><td>-5.316758  </td><td> 0.8890239 </td><td>4.966397   </td><td> 7.449851  </td><td> 3.800133  </td><td> 0.26145543</td><td>4.783851   </td><td>-2.2877002 </td><td> 2.8780960 </td></tr>\n",
       "\t<tr><th scope=row>109</th><td>  8.6897527</td><td>-6.034392  </td><td> 0.9717298 </td><td>5.068010   </td><td> 2.865280  </td><td> 2.787863  </td><td>-0.30287797</td><td>4.973354   </td><td> 5.9189989 </td><td> 3.1436115 </td></tr>\n",
       "\t<tr><th scope=row>110</th><td>  7.9672268</td><td>-6.926263  </td><td> 1.1240348 </td><td>5.049570   </td><td> 7.360189  </td><td> 3.518124  </td><td>-0.19915211</td><td>5.036292   </td><td> 5.9022122 </td><td> 3.3494032 </td></tr>\n",
       "\t<tr><th scope=row>113</th><td>  8.3893998</td><td>-4.697251  </td><td> 0.7684015 </td><td>5.329479   </td><td> 3.869399  </td><td> 4.830322  </td><td>-0.67696779</td><td>4.830815   </td><td> 0.1060806 </td><td> 6.3892685 </td></tr>\n",
       "\t<tr><th scope=row>114</th><td> 12.6024270</td><td>-6.063975  </td><td> 1.0182940 </td><td>4.658119   </td><td> 4.707501  </td><td> 4.345603  </td><td>-0.29726241</td><td>4.674973   </td><td>-0.7961403 </td><td> 9.4056615 </td></tr>\n",
       "\t<tr><th scope=row>115</th><td> -1.2543715</td><td>-4.224917  </td><td> 0.7138781 </td><td>5.423628   </td><td> 3.725064  </td><td> 4.074374  </td><td> 0.30797707</td><td>5.220737   </td><td> 7.9706540 </td><td> 8.2686908 </td></tr>\n",
       "\t<tr><th scope=row>118</th><td> -1.6277065</td><td>-6.318073  </td><td> 1.0134844 </td><td>5.900048   </td><td>14.300397  </td><td> 8.762880  </td><td>-1.14811355</td><td>4.192754   </td><td>-5.2312491 </td><td> 5.7403881 </td></tr>\n",
       "\t<tr><th scope=row>119</th><td>  0.5193747</td><td>-7.724431  </td><td> 1.3090078 </td><td>4.766258   </td><td>10.160292  </td><td> 9.552913  </td><td>-0.02462800</td><td>4.701746   </td><td> 0.6852970 </td><td> 7.0828966 </td></tr>\n",
       "\t<tr><th scope=row>121</th><td> -4.9126436</td><td>-6.187887  </td><td> 1.0086745 </td><td>5.000636   </td><td>10.964771  </td><td> 9.106856  </td><td> 0.24645618</td><td>4.739269   </td><td> 4.9710365 </td><td> 4.7331310 </td></tr>\n",
       "\t<tr><th scope=row>122</th><td> -8.3973058</td><td>-7.984448  </td><td> 1.2969869 </td><td>4.975438   </td><td>10.648186  </td><td>10.106910  </td><td> 0.66198369</td><td>4.400036   </td><td> 8.8851736 </td><td> 6.3548991 </td></tr>\n",
       "\t<tr><th scope=row>127</th><td> -7.6684027</td><td> 5.779708  </td><td>-0.9632910 </td><td>4.990941   </td><td> 2.957167  </td><td> 1.912165  </td><td> 0.08102273</td><td>4.802575   </td><td>-1.0306773 </td><td> 3.3453022 </td></tr>\n",
       "\t<tr><th scope=row>128</th><td> -8.9672995</td><td> 5.576580  </td><td>-0.9425780 </td><td>4.867637   </td><td> 4.410376  </td><td> 5.336272  </td><td> 0.22330198</td><td>5.040385   </td><td>-1.2382981 </td><td> 3.5628519 </td></tr>\n",
       "\t<tr><th scope=row>130</th><td> -9.7784518</td><td> 5.386655  </td><td>-0.8868555 </td><td>5.082620   </td><td> 2.240046  </td><td> 1.763074  </td><td>-0.07527220</td><td>5.156739   </td><td> 6.4218409 </td><td> 3.7889172 </td></tr>\n",
       "\t<tr><th scope=row>131</th><td>-10.1228433</td><td> 5.678132  </td><td>-1.0093673 </td><td>5.335545   </td><td> 6.248935  </td><td> 3.785975  </td><td>-0.22553667</td><td>5.143557   </td><td> 6.7329379 </td><td> 2.7873475 </td></tr>\n",
       "\t<tr><th scope=row>134</th><td> -5.1968928</td><td> 6.972898  </td><td>-1.1715631 </td><td>5.064275   </td><td> 4.231921  </td><td> 3.642066  </td><td>-0.34320860</td><td>5.010983   </td><td>-3.1142165 </td><td> 7.0992017 </td></tr>\n",
       "\t<tr><th scope=row>135</th><td>-12.3395725</td><td> 6.164698  </td><td>-1.0353523 </td><td>5.453402   </td><td> 3.198635  </td><td> 4.064074  </td><td>-0.59162293</td><td>4.870658   </td><td> 4.8296030 </td><td> 7.2948258 </td></tr>\n",
       "\t<tr><th scope=row>136</th><td>-16.0117273</td><td> 6.172229  </td><td>-1.0663003 </td><td>5.620617   </td><td> 3.172005  </td><td> 3.200763  </td><td> 0.43276234</td><td>5.485922   </td><td> 5.5242189 </td><td>12.7751907 </td></tr>\n",
       "\t<tr><th scope=row>139</th><td>-20.3612955</td><td> 5.455122  </td><td>-0.9103740 </td><td>5.145875   </td><td>10.854429  </td><td>10.199506  </td><td>-0.30544535</td><td>5.424512   </td><td>-1.3682680 </td><td> 3.7960883 </td></tr>\n",
       "\t<tr><th scope=row>140</th><td>-22.4499372</td><td> 7.044760  </td><td>-1.1602549 </td><td>5.316618   </td><td> 9.441823  </td><td>10.421556  </td><td>-0.50682409</td><td>5.358731   </td><td> 4.9942536 </td><td> 3.1250038 </td></tr>\n",
       "\t<tr><th scope=row>141</th><td>-24.9453753</td><td> 5.402571  </td><td>-0.8973809 </td><td>6.602328   </td><td>12.005472  </td><td> 8.605186  </td><td> 0.18697095</td><td>5.128337   </td><td> 3.2689854 </td><td> 8.8470019 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "  & (Intercept) & time & time2 & V1 & V2 & V3 & V45 & V301 & V302 & V303\\\\\n",
       "\\hline\n",
       "\t7 &  -6.349571   & -7.350222    &  1.2114900   & 4.171255     &  -6.8839144  &  -7.3718101  &  1.541683559 & 4.494505     & -0.7512000   & -3.9651174  \\\\\n",
       "\t8 &  -3.658046   & -6.883360    &  1.1881768   & 5.108242     &  -7.1688688  &  -5.0943271  &  0.057436244 & 4.526475     & -2.8828999   &  0.9714997  \\\\\n",
       "\t9 &  -3.698400   & -5.602412    &  0.9491308   & 5.115616     &  -8.6631469  &  -4.8501337  & -0.564776744 & 5.377504     & -1.5535279   &  6.3739251  \\\\\n",
       "\t12 &   2.665192   & -4.347118    &  0.7527754   & 5.103950     &  -1.2328158  &   1.2561532  & -0.003304848 & 4.863811     & -1.4622593   & -3.7378360  \\\\\n",
       "\t14 &   6.238134   & -6.017547    &  1.0210227   & 5.133300     &  -1.7202024  &  -0.8393982  &  0.049126577 & 5.055169     & -1.9300952   &  0.5422217  \\\\\n",
       "\t15 &   8.367578   & -5.629857    &  0.9427324   & 4.275650     &  -1.0969766  &  -0.2755758  &  0.054170399 & 4.870142     & -2.1582460   &  3.5697818  \\\\\n",
       "\t16 &  14.394620   & -6.824156    &  1.1617445   & 5.539400     &  -1.7106410  &  -0.9579946  &  0.793770034 & 5.224937     & -2.4107370   &  8.8672637  \\\\\n",
       "\t19 & -19.405325   &  4.318409    & -0.7500138   & 4.424966     &  -6.7462368  &  -6.0823057  &  1.608117424 & 5.017769     & -4.8821657   &  1.5511117  \\\\\n",
       "\t21 &  -6.724431   &  4.362079    & -0.7458413   & 5.397429     &  -0.8061076  &  -0.7187922  & -0.296876866 & 5.236399     & -7.0547208   &  2.7592528  \\\\\n",
       "\t22 & -12.449150   &  5.888207    & -0.9973595   & 5.003771     &  -0.4268434  &  -0.5087410  &  0.239971645 & 5.043480     & -3.7509750   & -0.5490829  \\\\\n",
       "\t24 & -22.044653   &  5.433242    & -0.9644557   & 5.271411     &  -7.5937295  &  -6.5730112  & -0.004060539 & 4.753809     & -0.1891438   &  3.9123291  \\\\\n",
       "\t27 & -13.551162   &  5.966522    & -0.9868972   & 5.307705     &  -1.2932211  &  -3.0401245  &  0.670361864 & 5.176984     &  0.4277795   & -3.2960232  \\\\\n",
       "\t28 & -10.729902   &  5.259813    & -0.8753016   & 5.043273     &  -0.2440885  &   0.1731477  & -0.017660917 & 5.015934     & -0.2169641   & -2.2637621  \\\\\n",
       "\t30 & -11.381880   &  7.176069    & -1.2332314   & 5.013619     &  -2.5695674  &  -1.1848845  & -0.026636250 & 5.171960     &  0.4868277   &  6.1654098  \\\\\n",
       "\t31 &  -8.662221   &  6.363031    & -1.0785895   & 5.292586     &   0.1361963  &  -0.9962916  & -0.254812035 & 5.154156     & -0.1956774   &  6.0314359  \\\\\n",
       "\t35 & -13.094860   & -7.752458    &  1.3391086   & 5.518346     &  -8.4232009  & -10.1897569  &  0.138806683 & 4.839941     &  5.0147350   &  2.6823288  \\\\\n",
       "\t38 &   4.807691   & -5.717462    &  0.9773386   & 5.737535     &  -3.9051448  &  -3.0201751  &  0.120116130 & 4.830966     &  3.7825144   & -2.2656989  \\\\\n",
       "\t39 &  12.448217   & -6.292740    &  1.0637098   & 5.085854     &  -0.3409647  &   2.4920219  & -0.264151860 & 4.869839     &  5.1598990   & -3.0776316  \\\\\n",
       "\t41 &   3.056057   & -6.231778    &  1.0580689   & 5.183706     &  -2.2687426  &  -2.9811756  & -0.178488353 & 5.046729     &  4.0875275   &  6.6090887  \\\\\n",
       "\t42 &   6.326519   & -5.409271    &  0.8787784   & 5.116082     &  -0.7725164  &   1.1414081  &  0.055282944 & 4.930518     &  5.0164417   &  5.4241915  \\\\\n",
       "\t45 &   7.819880   & -5.599724    &  0.9485516   & 5.194656     &  -6.0792588  &  -4.5591638  &  0.631989217 & 5.364900     &  9.2924404   & -3.9618229  \\\\\n",
       "\t46 &   9.164637   & -5.106353    &  0.8393423   & 4.752908     &   0.3195804  &  -1.7855249  & -0.481749671 & 4.975436     &  9.6274354   &  0.1891514  \\\\\n",
       "\t47 &  -1.259075   & -7.996618    &  1.3466470   & 5.154770     &  -2.8082342  &  -2.5625405  &  0.470185985 & 4.774474     & 11.4824890   &  7.0828526  \\\\\n",
       "\t50 & -21.912377   &  5.522484    & -0.9458886   & 4.965381     &  -6.1067589  &  -6.3365888  & -0.439651222 & 5.338519     &  4.0930690   &  1.8931533  \\\\\n",
       "\t51 & -27.836367   &  3.847604    & -0.6521752   & 4.444572     & -10.0806880  &  -8.1897339  &  2.273282076 & 5.185005     &  9.3469075   &  3.1153888  \\\\\n",
       "\t55 &  -8.001267   &  5.198383    & -0.8909435   & 5.753566     &  -1.3352775  &  -1.3551278  & -0.321050987 & 5.657438     &  3.4537616   & -5.2260658  \\\\\n",
       "\t56 &  -9.752904   &  5.893257    & -0.9540705   & 4.877735     &  -0.4143296  &  -1.6038974  & -0.167759645 & 5.296625     &  4.5660443   & -0.4736331  \\\\\n",
       "\t58 & -14.609936   &  6.127920    & -1.0328064   & 4.946224     &  -3.7773419  &  -1.5659736  &  0.213128245 & 4.984605     &  4.7634567   &  5.3403539  \\\\\n",
       "\t59 & -10.365922   &  5.686339    & -0.9591345   & 5.020290     &  -0.1211690  &   0.8767491  & -0.082980068 & 4.802946     &  5.1490904   &  4.4722205  \\\\\n",
       "\t61 &  -9.751992   &  5.489350    & -0.9272415   & 4.138274     &  -1.7790765  &  -0.2289724  &  0.456656967 & 5.154154     &  8.7488899   &  1.9197987  \\\\\n",
       "\t... & ... & ... & ... & ... & ... & ... & ... & ... & ... & ...\\\\\n",
       "\t87 & -15.7689421 &  4.524557   & -0.7310722  & 5.365526    &  3.822468   &  4.190592   & -0.70645722 & 4.845132    & -3.4498033  & -5.5562817 \\\\\n",
       "\t88 & -11.8596058 &  5.966243   & -1.0022988  & 5.357427    &  3.409241   &  2.994849   &  0.13689597 & 4.988578    & -3.0599572  & -0.7054587 \\\\\n",
       "\t91 &  -5.2930163 &  5.474512   & -0.9384664  & 4.970255    &  3.963720   &  2.577223   & -0.07005220 & 4.927862    &  4.1547767  & -4.0691930 \\\\\n",
       "\t92 &  -6.8224427 &  5.187634   & -0.8530157  & 4.674332    &  3.429878   &  3.530035   & -0.06011514 & 5.018971    &  5.1743709  & -0.4107791 \\\\\n",
       "\t93 &  -0.2213838 &  5.242802   & -0.8525191  & 4.917581    &  4.078965   &  2.332487   &  0.36268627 & 5.290928    &  9.5074379  & -3.3375099 \\\\\n",
       "\t96 & -10.8692317 &  4.588524   & -0.7802483  & 5.383366    &  5.404228   &  8.552615   &  0.74589154 & 4.611610    &  3.2153187  & -4.5617277 \\\\\n",
       "\t97 & -24.7509425 &  5.572279   & -1.0431289  & 4.475659    &  8.251356   & 10.303484   &  2.46279933 & 4.531958    & -1.2509979  & -5.4946947 \\\\\n",
       "\t99 & -18.7608026 &  4.871280   & -0.8348056  & 4.907792    &  8.795497   &  9.763008   &  0.05920735 & 5.383504    & -1.7514458  & -0.2796193 \\\\\n",
       "\t100 & -16.6772449 &  6.482455   & -1.0548595  & 4.781487    &  9.013663   &  9.151572   & -0.12029910 & 4.716647    &  7.2613030  & -0.1448964 \\\\\n",
       "\t106 &   9.3941321 & -5.884971   &  0.9764701  & 4.551538    &  2.963078   &  3.341592   &  0.32235186 & 5.065561    & -0.9709176  &  3.0570445 \\\\\n",
       "\t107 &   6.9809196 & -5.316758   &  0.8890239  & 4.966397    &  7.449851   &  3.800133   &  0.26145543 & 4.783851    & -2.2877002  &  2.8780960 \\\\\n",
       "\t109 &   8.6897527 & -6.034392   &  0.9717298  & 5.068010    &  2.865280   &  2.787863   & -0.30287797 & 4.973354    &  5.9189989  &  3.1436115 \\\\\n",
       "\t110 &   7.9672268 & -6.926263   &  1.1240348  & 5.049570    &  7.360189   &  3.518124   & -0.19915211 & 5.036292    &  5.9022122  &  3.3494032 \\\\\n",
       "\t113 &   8.3893998 & -4.697251   &  0.7684015  & 5.329479    &  3.869399   &  4.830322   & -0.67696779 & 4.830815    &  0.1060806  &  6.3892685 \\\\\n",
       "\t114 &  12.6024270 & -6.063975   &  1.0182940  & 4.658119    &  4.707501   &  4.345603   & -0.29726241 & 4.674973    & -0.7961403  &  9.4056615 \\\\\n",
       "\t115 &  -1.2543715 & -4.224917   &  0.7138781  & 5.423628    &  3.725064   &  4.074374   &  0.30797707 & 5.220737    &  7.9706540  &  8.2686908 \\\\\n",
       "\t118 &  -1.6277065 & -6.318073   &  1.0134844  & 5.900048    & 14.300397   &  8.762880   & -1.14811355 & 4.192754    & -5.2312491  &  5.7403881 \\\\\n",
       "\t119 &   0.5193747 & -7.724431   &  1.3090078  & 4.766258    & 10.160292   &  9.552913   & -0.02462800 & 4.701746    &  0.6852970  &  7.0828966 \\\\\n",
       "\t121 &  -4.9126436 & -6.187887   &  1.0086745  & 5.000636    & 10.964771   &  9.106856   &  0.24645618 & 4.739269    &  4.9710365  &  4.7331310 \\\\\n",
       "\t122 &  -8.3973058 & -7.984448   &  1.2969869  & 4.975438    & 10.648186   & 10.106910   &  0.66198369 & 4.400036    &  8.8851736  &  6.3548991 \\\\\n",
       "\t127 &  -7.6684027 &  5.779708   & -0.9632910  & 4.990941    &  2.957167   &  1.912165   &  0.08102273 & 4.802575    & -1.0306773  &  3.3453022 \\\\\n",
       "\t128 &  -8.9672995 &  5.576580   & -0.9425780  & 4.867637    &  4.410376   &  5.336272   &  0.22330198 & 5.040385    & -1.2382981  &  3.5628519 \\\\\n",
       "\t130 &  -9.7784518 &  5.386655   & -0.8868555  & 5.082620    &  2.240046   &  1.763074   & -0.07527220 & 5.156739    &  6.4218409  &  3.7889172 \\\\\n",
       "\t131 & -10.1228433 &  5.678132   & -1.0093673  & 5.335545    &  6.248935   &  3.785975   & -0.22553667 & 5.143557    &  6.7329379  &  2.7873475 \\\\\n",
       "\t134 &  -5.1968928 &  6.972898   & -1.1715631  & 5.064275    &  4.231921   &  3.642066   & -0.34320860 & 5.010983    & -3.1142165  &  7.0992017 \\\\\n",
       "\t135 & -12.3395725 &  6.164698   & -1.0353523  & 5.453402    &  3.198635   &  4.064074   & -0.59162293 & 4.870658    &  4.8296030  &  7.2948258 \\\\\n",
       "\t136 & -16.0117273 &  6.172229   & -1.0663003  & 5.620617    &  3.172005   &  3.200763   &  0.43276234 & 5.485922    &  5.5242189  & 12.7751907 \\\\\n",
       "\t139 & -20.3612955 &  5.455122   & -0.9103740  & 5.145875    & 10.854429   & 10.199506   & -0.30544535 & 5.424512    & -1.3682680  &  3.7960883 \\\\\n",
       "\t140 & -22.4499372 &  7.044760   & -1.1602549  & 5.316618    &  9.441823   & 10.421556   & -0.50682409 & 5.358731    &  4.9942536  &  3.1250038 \\\\\n",
       "\t141 & -24.9453753 &  5.402571   & -0.8973809  & 6.602328    & 12.005472   &  8.605186   &  0.18697095 & 5.128337    &  3.2689854  &  8.8470019 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | (Intercept) | time | time2 | V1 | V2 | V3 | V45 | V301 | V302 | V303 |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 7 |  -6.349571   | -7.350222    |  1.2114900   | 4.171255     |  -6.8839144  |  -7.3718101  |  1.541683559 | 4.494505     | -0.7512000   | -3.9651174   |\n",
       "| 8 |  -3.658046   | -6.883360    |  1.1881768   | 5.108242     |  -7.1688688  |  -5.0943271  |  0.057436244 | 4.526475     | -2.8828999   |  0.9714997   |\n",
       "| 9 |  -3.698400   | -5.602412    |  0.9491308   | 5.115616     |  -8.6631469  |  -4.8501337  | -0.564776744 | 5.377504     | -1.5535279   |  6.3739251   |\n",
       "| 12 |   2.665192   | -4.347118    |  0.7527754   | 5.103950     |  -1.2328158  |   1.2561532  | -0.003304848 | 4.863811     | -1.4622593   | -3.7378360   |\n",
       "| 14 |   6.238134   | -6.017547    |  1.0210227   | 5.133300     |  -1.7202024  |  -0.8393982  |  0.049126577 | 5.055169     | -1.9300952   |  0.5422217   |\n",
       "| 15 |   8.367578   | -5.629857    |  0.9427324   | 4.275650     |  -1.0969766  |  -0.2755758  |  0.054170399 | 4.870142     | -2.1582460   |  3.5697818   |\n",
       "| 16 |  14.394620   | -6.824156    |  1.1617445   | 5.539400     |  -1.7106410  |  -0.9579946  |  0.793770034 | 5.224937     | -2.4107370   |  8.8672637   |\n",
       "| 19 | -19.405325   |  4.318409    | -0.7500138   | 4.424966     |  -6.7462368  |  -6.0823057  |  1.608117424 | 5.017769     | -4.8821657   |  1.5511117   |\n",
       "| 21 |  -6.724431   |  4.362079    | -0.7458413   | 5.397429     |  -0.8061076  |  -0.7187922  | -0.296876866 | 5.236399     | -7.0547208   |  2.7592528   |\n",
       "| 22 | -12.449150   |  5.888207    | -0.9973595   | 5.003771     |  -0.4268434  |  -0.5087410  |  0.239971645 | 5.043480     | -3.7509750   | -0.5490829   |\n",
       "| 24 | -22.044653   |  5.433242    | -0.9644557   | 5.271411     |  -7.5937295  |  -6.5730112  | -0.004060539 | 4.753809     | -0.1891438   |  3.9123291   |\n",
       "| 27 | -13.551162   |  5.966522    | -0.9868972   | 5.307705     |  -1.2932211  |  -3.0401245  |  0.670361864 | 5.176984     |  0.4277795   | -3.2960232   |\n",
       "| 28 | -10.729902   |  5.259813    | -0.8753016   | 5.043273     |  -0.2440885  |   0.1731477  | -0.017660917 | 5.015934     | -0.2169641   | -2.2637621   |\n",
       "| 30 | -11.381880   |  7.176069    | -1.2332314   | 5.013619     |  -2.5695674  |  -1.1848845  | -0.026636250 | 5.171960     |  0.4868277   |  6.1654098   |\n",
       "| 31 |  -8.662221   |  6.363031    | -1.0785895   | 5.292586     |   0.1361963  |  -0.9962916  | -0.254812035 | 5.154156     | -0.1956774   |  6.0314359   |\n",
       "| 35 | -13.094860   | -7.752458    |  1.3391086   | 5.518346     |  -8.4232009  | -10.1897569  |  0.138806683 | 4.839941     |  5.0147350   |  2.6823288   |\n",
       "| 38 |   4.807691   | -5.717462    |  0.9773386   | 5.737535     |  -3.9051448  |  -3.0201751  |  0.120116130 | 4.830966     |  3.7825144   | -2.2656989   |\n",
       "| 39 |  12.448217   | -6.292740    |  1.0637098   | 5.085854     |  -0.3409647  |   2.4920219  | -0.264151860 | 4.869839     |  5.1598990   | -3.0776316   |\n",
       "| 41 |   3.056057   | -6.231778    |  1.0580689   | 5.183706     |  -2.2687426  |  -2.9811756  | -0.178488353 | 5.046729     |  4.0875275   |  6.6090887   |\n",
       "| 42 |   6.326519   | -5.409271    |  0.8787784   | 5.116082     |  -0.7725164  |   1.1414081  |  0.055282944 | 4.930518     |  5.0164417   |  5.4241915   |\n",
       "| 45 |   7.819880   | -5.599724    |  0.9485516   | 5.194656     |  -6.0792588  |  -4.5591638  |  0.631989217 | 5.364900     |  9.2924404   | -3.9618229   |\n",
       "| 46 |   9.164637   | -5.106353    |  0.8393423   | 4.752908     |   0.3195804  |  -1.7855249  | -0.481749671 | 4.975436     |  9.6274354   |  0.1891514   |\n",
       "| 47 |  -1.259075   | -7.996618    |  1.3466470   | 5.154770     |  -2.8082342  |  -2.5625405  |  0.470185985 | 4.774474     | 11.4824890   |  7.0828526   |\n",
       "| 50 | -21.912377   |  5.522484    | -0.9458886   | 4.965381     |  -6.1067589  |  -6.3365888  | -0.439651222 | 5.338519     |  4.0930690   |  1.8931533   |\n",
       "| 51 | -27.836367   |  3.847604    | -0.6521752   | 4.444572     | -10.0806880  |  -8.1897339  |  2.273282076 | 5.185005     |  9.3469075   |  3.1153888   |\n",
       "| 55 |  -8.001267   |  5.198383    | -0.8909435   | 5.753566     |  -1.3352775  |  -1.3551278  | -0.321050987 | 5.657438     |  3.4537616   | -5.2260658   |\n",
       "| 56 |  -9.752904   |  5.893257    | -0.9540705   | 4.877735     |  -0.4143296  |  -1.6038974  | -0.167759645 | 5.296625     |  4.5660443   | -0.4736331   |\n",
       "| 58 | -14.609936   |  6.127920    | -1.0328064   | 4.946224     |  -3.7773419  |  -1.5659736  |  0.213128245 | 4.984605     |  4.7634567   |  5.3403539   |\n",
       "| 59 | -10.365922   |  5.686339    | -0.9591345   | 5.020290     |  -0.1211690  |   0.8767491  | -0.082980068 | 4.802946     |  5.1490904   |  4.4722205   |\n",
       "| 61 |  -9.751992   |  5.489350    | -0.9272415   | 4.138274     |  -1.7790765  |  -0.2289724  |  0.456656967 | 5.154154     |  8.7488899   |  1.9197987   |\n",
       "| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
       "| 87 | -15.7689421 |  4.524557   | -0.7310722  | 5.365526    |  3.822468   |  4.190592   | -0.70645722 | 4.845132    | -3.4498033  | -5.5562817  |\n",
       "| 88 | -11.8596058 |  5.966243   | -1.0022988  | 5.357427    |  3.409241   |  2.994849   |  0.13689597 | 4.988578    | -3.0599572  | -0.7054587  |\n",
       "| 91 |  -5.2930163 |  5.474512   | -0.9384664  | 4.970255    |  3.963720   |  2.577223   | -0.07005220 | 4.927862    |  4.1547767  | -4.0691930  |\n",
       "| 92 |  -6.8224427 |  5.187634   | -0.8530157  | 4.674332    |  3.429878   |  3.530035   | -0.06011514 | 5.018971    |  5.1743709  | -0.4107791  |\n",
       "| 93 |  -0.2213838 |  5.242802   | -0.8525191  | 4.917581    |  4.078965   |  2.332487   |  0.36268627 | 5.290928    |  9.5074379  | -3.3375099  |\n",
       "| 96 | -10.8692317 |  4.588524   | -0.7802483  | 5.383366    |  5.404228   |  8.552615   |  0.74589154 | 4.611610    |  3.2153187  | -4.5617277  |\n",
       "| 97 | -24.7509425 |  5.572279   | -1.0431289  | 4.475659    |  8.251356   | 10.303484   |  2.46279933 | 4.531958    | -1.2509979  | -5.4946947  |\n",
       "| 99 | -18.7608026 |  4.871280   | -0.8348056  | 4.907792    |  8.795497   |  9.763008   |  0.05920735 | 5.383504    | -1.7514458  | -0.2796193  |\n",
       "| 100 | -16.6772449 |  6.482455   | -1.0548595  | 4.781487    |  9.013663   |  9.151572   | -0.12029910 | 4.716647    |  7.2613030  | -0.1448964  |\n",
       "| 106 |   9.3941321 | -5.884971   |  0.9764701  | 4.551538    |  2.963078   |  3.341592   |  0.32235186 | 5.065561    | -0.9709176  |  3.0570445  |\n",
       "| 107 |   6.9809196 | -5.316758   |  0.8890239  | 4.966397    |  7.449851   |  3.800133   |  0.26145543 | 4.783851    | -2.2877002  |  2.8780960  |\n",
       "| 109 |   8.6897527 | -6.034392   |  0.9717298  | 5.068010    |  2.865280   |  2.787863   | -0.30287797 | 4.973354    |  5.9189989  |  3.1436115  |\n",
       "| 110 |   7.9672268 | -6.926263   |  1.1240348  | 5.049570    |  7.360189   |  3.518124   | -0.19915211 | 5.036292    |  5.9022122  |  3.3494032  |\n",
       "| 113 |   8.3893998 | -4.697251   |  0.7684015  | 5.329479    |  3.869399   |  4.830322   | -0.67696779 | 4.830815    |  0.1060806  |  6.3892685  |\n",
       "| 114 |  12.6024270 | -6.063975   |  1.0182940  | 4.658119    |  4.707501   |  4.345603   | -0.29726241 | 4.674973    | -0.7961403  |  9.4056615  |\n",
       "| 115 |  -1.2543715 | -4.224917   |  0.7138781  | 5.423628    |  3.725064   |  4.074374   |  0.30797707 | 5.220737    |  7.9706540  |  8.2686908  |\n",
       "| 118 |  -1.6277065 | -6.318073   |  1.0134844  | 5.900048    | 14.300397   |  8.762880   | -1.14811355 | 4.192754    | -5.2312491  |  5.7403881  |\n",
       "| 119 |   0.5193747 | -7.724431   |  1.3090078  | 4.766258    | 10.160292   |  9.552913   | -0.02462800 | 4.701746    |  0.6852970  |  7.0828966  |\n",
       "| 121 |  -4.9126436 | -6.187887   |  1.0086745  | 5.000636    | 10.964771   |  9.106856   |  0.24645618 | 4.739269    |  4.9710365  |  4.7331310  |\n",
       "| 122 |  -8.3973058 | -7.984448   |  1.2969869  | 4.975438    | 10.648186   | 10.106910   |  0.66198369 | 4.400036    |  8.8851736  |  6.3548991  |\n",
       "| 127 |  -7.6684027 |  5.779708   | -0.9632910  | 4.990941    |  2.957167   |  1.912165   |  0.08102273 | 4.802575    | -1.0306773  |  3.3453022  |\n",
       "| 128 |  -8.9672995 |  5.576580   | -0.9425780  | 4.867637    |  4.410376   |  5.336272   |  0.22330198 | 5.040385    | -1.2382981  |  3.5628519  |\n",
       "| 130 |  -9.7784518 |  5.386655   | -0.8868555  | 5.082620    |  2.240046   |  1.763074   | -0.07527220 | 5.156739    |  6.4218409  |  3.7889172  |\n",
       "| 131 | -10.1228433 |  5.678132   | -1.0093673  | 5.335545    |  6.248935   |  3.785975   | -0.22553667 | 5.143557    |  6.7329379  |  2.7873475  |\n",
       "| 134 |  -5.1968928 |  6.972898   | -1.1715631  | 5.064275    |  4.231921   |  3.642066   | -0.34320860 | 5.010983    | -3.1142165  |  7.0992017  |\n",
       "| 135 | -12.3395725 |  6.164698   | -1.0353523  | 5.453402    |  3.198635   |  4.064074   | -0.59162293 | 4.870658    |  4.8296030  |  7.2948258  |\n",
       "| 136 | -16.0117273 |  6.172229   | -1.0663003  | 5.620617    |  3.172005   |  3.200763   |  0.43276234 | 5.485922    |  5.5242189  | 12.7751907  |\n",
       "| 139 | -20.3612955 |  5.455122   | -0.9103740  | 5.145875    | 10.854429   | 10.199506   | -0.30544535 | 5.424512    | -1.3682680  |  3.7960883  |\n",
       "| 140 | -22.4499372 |  7.044760   | -1.1602549  | 5.316618    |  9.441823   | 10.421556   | -0.50682409 | 5.358731    |  4.9942536  |  3.1250038  |\n",
       "| 141 | -24.9453753 |  5.402571   | -0.8973809  | 6.602328    | 12.005472   |  8.605186   |  0.18697095 | 5.128337    |  3.2689854  |  8.8470019  |\n",
       "\n"
      ],
      "text/plain": [
       "    (Intercept) time      time2      V1       V2          V3         \n",
       "7    -6.349571  -7.350222  1.2114900 4.171255  -6.8839144  -7.3718101\n",
       "8    -3.658046  -6.883360  1.1881768 5.108242  -7.1688688  -5.0943271\n",
       "9    -3.698400  -5.602412  0.9491308 5.115616  -8.6631469  -4.8501337\n",
       "12    2.665192  -4.347118  0.7527754 5.103950  -1.2328158   1.2561532\n",
       "14    6.238134  -6.017547  1.0210227 5.133300  -1.7202024  -0.8393982\n",
       "15    8.367578  -5.629857  0.9427324 4.275650  -1.0969766  -0.2755758\n",
       "16   14.394620  -6.824156  1.1617445 5.539400  -1.7106410  -0.9579946\n",
       "19  -19.405325   4.318409 -0.7500138 4.424966  -6.7462368  -6.0823057\n",
       "21   -6.724431   4.362079 -0.7458413 5.397429  -0.8061076  -0.7187922\n",
       "22  -12.449150   5.888207 -0.9973595 5.003771  -0.4268434  -0.5087410\n",
       "24  -22.044653   5.433242 -0.9644557 5.271411  -7.5937295  -6.5730112\n",
       "27  -13.551162   5.966522 -0.9868972 5.307705  -1.2932211  -3.0401245\n",
       "28  -10.729902   5.259813 -0.8753016 5.043273  -0.2440885   0.1731477\n",
       "30  -11.381880   7.176069 -1.2332314 5.013619  -2.5695674  -1.1848845\n",
       "31   -8.662221   6.363031 -1.0785895 5.292586   0.1361963  -0.9962916\n",
       "35  -13.094860  -7.752458  1.3391086 5.518346  -8.4232009 -10.1897569\n",
       "38    4.807691  -5.717462  0.9773386 5.737535  -3.9051448  -3.0201751\n",
       "39   12.448217  -6.292740  1.0637098 5.085854  -0.3409647   2.4920219\n",
       "41    3.056057  -6.231778  1.0580689 5.183706  -2.2687426  -2.9811756\n",
       "42    6.326519  -5.409271  0.8787784 5.116082  -0.7725164   1.1414081\n",
       "45    7.819880  -5.599724  0.9485516 5.194656  -6.0792588  -4.5591638\n",
       "46    9.164637  -5.106353  0.8393423 4.752908   0.3195804  -1.7855249\n",
       "47   -1.259075  -7.996618  1.3466470 5.154770  -2.8082342  -2.5625405\n",
       "50  -21.912377   5.522484 -0.9458886 4.965381  -6.1067589  -6.3365888\n",
       "51  -27.836367   3.847604 -0.6521752 4.444572 -10.0806880  -8.1897339\n",
       "55   -8.001267   5.198383 -0.8909435 5.753566  -1.3352775  -1.3551278\n",
       "56   -9.752904   5.893257 -0.9540705 4.877735  -0.4143296  -1.6038974\n",
       "58  -14.609936   6.127920 -1.0328064 4.946224  -3.7773419  -1.5659736\n",
       "59  -10.365922   5.686339 -0.9591345 5.020290  -0.1211690   0.8767491\n",
       "61   -9.751992   5.489350 -0.9272415 4.138274  -1.7790765  -0.2289724\n",
       "... ...         ...       ...        ...      ...         ...        \n",
       "87  -15.7689421  4.524557 -0.7310722 5.365526  3.822468    4.190592  \n",
       "88  -11.8596058  5.966243 -1.0022988 5.357427  3.409241    2.994849  \n",
       "91   -5.2930163  5.474512 -0.9384664 4.970255  3.963720    2.577223  \n",
       "92   -6.8224427  5.187634 -0.8530157 4.674332  3.429878    3.530035  \n",
       "93   -0.2213838  5.242802 -0.8525191 4.917581  4.078965    2.332487  \n",
       "96  -10.8692317  4.588524 -0.7802483 5.383366  5.404228    8.552615  \n",
       "97  -24.7509425  5.572279 -1.0431289 4.475659  8.251356   10.303484  \n",
       "99  -18.7608026  4.871280 -0.8348056 4.907792  8.795497    9.763008  \n",
       "100 -16.6772449  6.482455 -1.0548595 4.781487  9.013663    9.151572  \n",
       "106   9.3941321 -5.884971  0.9764701 4.551538  2.963078    3.341592  \n",
       "107   6.9809196 -5.316758  0.8890239 4.966397  7.449851    3.800133  \n",
       "109   8.6897527 -6.034392  0.9717298 5.068010  2.865280    2.787863  \n",
       "110   7.9672268 -6.926263  1.1240348 5.049570  7.360189    3.518124  \n",
       "113   8.3893998 -4.697251  0.7684015 5.329479  3.869399    4.830322  \n",
       "114  12.6024270 -6.063975  1.0182940 4.658119  4.707501    4.345603  \n",
       "115  -1.2543715 -4.224917  0.7138781 5.423628  3.725064    4.074374  \n",
       "118  -1.6277065 -6.318073  1.0134844 5.900048 14.300397    8.762880  \n",
       "119   0.5193747 -7.724431  1.3090078 4.766258 10.160292    9.552913  \n",
       "121  -4.9126436 -6.187887  1.0086745 5.000636 10.964771    9.106856  \n",
       "122  -8.3973058 -7.984448  1.2969869 4.975438 10.648186   10.106910  \n",
       "127  -7.6684027  5.779708 -0.9632910 4.990941  2.957167    1.912165  \n",
       "128  -8.9672995  5.576580 -0.9425780 4.867637  4.410376    5.336272  \n",
       "130  -9.7784518  5.386655 -0.8868555 5.082620  2.240046    1.763074  \n",
       "131 -10.1228433  5.678132 -1.0093673 5.335545  6.248935    3.785975  \n",
       "134  -5.1968928  6.972898 -1.1715631 5.064275  4.231921    3.642066  \n",
       "135 -12.3395725  6.164698 -1.0353523 5.453402  3.198635    4.064074  \n",
       "136 -16.0117273  6.172229 -1.0663003 5.620617  3.172005    3.200763  \n",
       "139 -20.3612955  5.455122 -0.9103740 5.145875 10.854429   10.199506  \n",
       "140 -22.4499372  7.044760 -1.1602549 5.316618  9.441823   10.421556  \n",
       "141 -24.9453753  5.402571 -0.8973809 6.602328 12.005472    8.605186  \n",
       "    V45          V301     V302       V303      \n",
       "7    1.541683559 4.494505 -0.7512000 -3.9651174\n",
       "8    0.057436244 4.526475 -2.8828999  0.9714997\n",
       "9   -0.564776744 5.377504 -1.5535279  6.3739251\n",
       "12  -0.003304848 4.863811 -1.4622593 -3.7378360\n",
       "14   0.049126577 5.055169 -1.9300952  0.5422217\n",
       "15   0.054170399 4.870142 -2.1582460  3.5697818\n",
       "16   0.793770034 5.224937 -2.4107370  8.8672637\n",
       "19   1.608117424 5.017769 -4.8821657  1.5511117\n",
       "21  -0.296876866 5.236399 -7.0547208  2.7592528\n",
       "22   0.239971645 5.043480 -3.7509750 -0.5490829\n",
       "24  -0.004060539 4.753809 -0.1891438  3.9123291\n",
       "27   0.670361864 5.176984  0.4277795 -3.2960232\n",
       "28  -0.017660917 5.015934 -0.2169641 -2.2637621\n",
       "30  -0.026636250 5.171960  0.4868277  6.1654098\n",
       "31  -0.254812035 5.154156 -0.1956774  6.0314359\n",
       "35   0.138806683 4.839941  5.0147350  2.6823288\n",
       "38   0.120116130 4.830966  3.7825144 -2.2656989\n",
       "39  -0.264151860 4.869839  5.1598990 -3.0776316\n",
       "41  -0.178488353 5.046729  4.0875275  6.6090887\n",
       "42   0.055282944 4.930518  5.0164417  5.4241915\n",
       "45   0.631989217 5.364900  9.2924404 -3.9618229\n",
       "46  -0.481749671 4.975436  9.6274354  0.1891514\n",
       "47   0.470185985 4.774474 11.4824890  7.0828526\n",
       "50  -0.439651222 5.338519  4.0930690  1.8931533\n",
       "51   2.273282076 5.185005  9.3469075  3.1153888\n",
       "55  -0.321050987 5.657438  3.4537616 -5.2260658\n",
       "56  -0.167759645 5.296625  4.5660443 -0.4736331\n",
       "58   0.213128245 4.984605  4.7634567  5.3403539\n",
       "59  -0.082980068 4.802946  5.1490904  4.4722205\n",
       "61   0.456656967 5.154154  8.7488899  1.9197987\n",
       "... ...          ...      ...        ...       \n",
       "87  -0.70645722  4.845132 -3.4498033 -5.5562817\n",
       "88   0.13689597  4.988578 -3.0599572 -0.7054587\n",
       "91  -0.07005220  4.927862  4.1547767 -4.0691930\n",
       "92  -0.06011514  5.018971  5.1743709 -0.4107791\n",
       "93   0.36268627  5.290928  9.5074379 -3.3375099\n",
       "96   0.74589154  4.611610  3.2153187 -4.5617277\n",
       "97   2.46279933  4.531958 -1.2509979 -5.4946947\n",
       "99   0.05920735  5.383504 -1.7514458 -0.2796193\n",
       "100 -0.12029910  4.716647  7.2613030 -0.1448964\n",
       "106  0.32235186  5.065561 -0.9709176  3.0570445\n",
       "107  0.26145543  4.783851 -2.2877002  2.8780960\n",
       "109 -0.30287797  4.973354  5.9189989  3.1436115\n",
       "110 -0.19915211  5.036292  5.9022122  3.3494032\n",
       "113 -0.67696779  4.830815  0.1060806  6.3892685\n",
       "114 -0.29726241  4.674973 -0.7961403  9.4056615\n",
       "115  0.30797707  5.220737  7.9706540  8.2686908\n",
       "118 -1.14811355  4.192754 -5.2312491  5.7403881\n",
       "119 -0.02462800  4.701746  0.6852970  7.0828966\n",
       "121  0.24645618  4.739269  4.9710365  4.7331310\n",
       "122  0.66198369  4.400036  8.8851736  6.3548991\n",
       "127  0.08102273  4.802575 -1.0306773  3.3453022\n",
       "128  0.22330198  5.040385 -1.2382981  3.5628519\n",
       "130 -0.07527220  5.156739  6.4218409  3.7889172\n",
       "131 -0.22553667  5.143557  6.7329379  2.7873475\n",
       "134 -0.34320860  5.010983 -3.1142165  7.0992017\n",
       "135 -0.59162293  4.870658  4.8296030  7.2948258\n",
       "136  0.43276234  5.485922  5.5242189 12.7751907\n",
       "139 -0.30544535  5.424512 -1.3682680  3.7960883\n",
       "140 -0.50682409  5.358731  4.9942536  3.1250038\n",
       "141  0.18697095  5.128337  3.2689854  8.8470019"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fuzzy=TRUE \n",
    "# alpha = 0.2, maxdepth_factor_select = 0.8 \n",
    "system.time({\n",
    "    mytree = Longtree(data,fixed_regress=fixed_regress,fixed_split=fixed_split,\n",
    "                  var_select=var_select,cluster=cluster,Fuzzy=TRUE,\n",
    "                     maxdepth_factor_select = 0.8,minsize_multiplier=5)\n",
    "})\n",
    "mean((predict(mytree,newdata=data_test,re.form=NA)-data_test$y)**2)\n",
    "coef(mytree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy=TRUE \n",
    "# alpha = 0.2, maxdepth_factor_select = 0.5 (all default)\n",
    "system.time({\n",
    "    mytree = Longtree(data,fixed_regress=fixed_regress,fixed_split=fixed_split,\n",
    "                  var_select=var_select,cluster=cluster,Fuzzy=TRUE)\n",
    "})\n",
    "mean((predict(mytree,newdata=data_test,re.form=NA)-data_test$y)**2)\n",
    "coef(mytree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "library(\"randomForest\")\n",
    "var = c(paste(\"V\",1:400,sep=\"\"),\"time\",\"time2\",\"treatment\")\n",
    "Formula = as.formula(paste(\"y~\",paste(var,collapse = \"+\")))\n",
    "system.time({\n",
    "#     set.seed(20)\n",
    "    rf <- randomForest(Formula,data)\n",
    "})\n",
    "mean((predict(rf,newdata=data_test)-data_test$y)**2)\n",
    "# sorts features by importance\n",
    "importance_order <- sort(rf$importance, decreasing = TRUE,index.return=TRUE) \n",
    "# the ranking; 6 here should be a parameters\n",
    "var[importance_order$ix[1:15]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var[importance_order$ix] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'fuzzyforest' was built under R version 3.6.1\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "3384.45    8.99 3405.07 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "25.6646643395916"
      ],
      "text/latex": [
       "25.6646643395916"
      ],
      "text/markdown": [
       "25.6646643395916"
      ],
      "text/plain": [
       "[1] 25.66466"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'V3'</li>\n",
       "\t<li>'V1'</li>\n",
       "\t<li>'V301'</li>\n",
       "\t<li>'V2'</li>\n",
       "\t<li>'V303'</li>\n",
       "\t<li>'V302'</li>\n",
       "\t<li>'V95'</li>\n",
       "\t<li>'V44'</li>\n",
       "\t<li>'treatment'</li>\n",
       "\t<li>'V142'</li>\n",
       "\t<li>'V180'</li>\n",
       "\t<li>'V128'</li>\n",
       "\t<li>'V260'</li>\n",
       "\t<li>'V274'</li>\n",
       "\t<li>'V242'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'V3'\n",
       "\\item 'V1'\n",
       "\\item 'V301'\n",
       "\\item 'V2'\n",
       "\\item 'V303'\n",
       "\\item 'V302'\n",
       "\\item 'V95'\n",
       "\\item 'V44'\n",
       "\\item 'treatment'\n",
       "\\item 'V142'\n",
       "\\item 'V180'\n",
       "\\item 'V128'\n",
       "\\item 'V260'\n",
       "\\item 'V274'\n",
       "\\item 'V242'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'V3'\n",
       "2. 'V1'\n",
       "3. 'V301'\n",
       "4. 'V2'\n",
       "5. 'V303'\n",
       "6. 'V302'\n",
       "7. 'V95'\n",
       "8. 'V44'\n",
       "9. 'treatment'\n",
       "10. 'V142'\n",
       "11. 'V180'\n",
       "12. 'V128'\n",
       "13. 'V260'\n",
       "14. 'V274'\n",
       "15. 'V242'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"V3\"        \"V1\"        \"V301\"      \"V2\"        \"V303\"      \"V302\"     \n",
       " [7] \"V95\"       \"V44\"       \"treatment\" \"V142\"      \"V180\"      \"V128\"     \n",
       "[13] \"V260\"      \"V274\"      \"V242\"     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fuzzy Forest\n",
    "library(\"fuzzyforest\")\n",
    "# since treatment is categorical, we cannot include it in WGCNA\n",
    "system.time({\n",
    "data_WGCNA = data[,1:400] # only the covariates\n",
    "\n",
    "net = blockwiseModules(data_WGCNA, power = 6,TOMType = \"unsigned\", \n",
    "                       minModuleSize = 30,reassignThreshold = 0, \n",
    "                       mergeCutHeight = 0.25,numericLabels = FALSE, \n",
    "                       pamRespectsDendro = FALSE,verbose = 0)\n",
    "\n",
    "var = c(paste(\"V\",1:400,sep=\"\"),\"time\",\"time2\",\"treatment\")\n",
    "Formula = as.formula(paste(\"y~\",paste(var,collapse = \"+\")))\n",
    "    \n",
    "net$colors[[\"time\"]] = \"grey\"\n",
    "net$colors[[\"time2\"]] = \"grey\"\n",
    "net$colors[[\"treatment\"]] = \"grey\"\n",
    "\n",
    "ff_fit = ff(Formula,data = data,module_membership=net$colors,\n",
    "        screen_params = screen_control(min_ntree = 500),\n",
    "        select_params = select_control(min_ntree = 500,number_selected = 15), \n",
    "        final_ntree = 5000, num_processors = 1)        \n",
    "})\n",
    "mean((predict(ff_fit,new_data=data_test)-data_test$y)**2)\n",
    "ff_fit$feature_list[,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
